Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,Document Type,Publication Stage,Open Access,Source,EID
"Dagnino F.","57190810538;","A Meta-theory for Big-step Semantics",2022,"ACM Transactions on Computational Logic","23","3","20","","",,,"10.1145/3522729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135009157&doi=10.1145%2f3522729&partnerID=40&md5=c66dd8fcda6e8333980ac22378171491","It is well known that big-step semantics is not able to distinguish stuck and non-terminating computations. This is a strong limitation as it makes it very difficult to reason about properties involving infinite computations, such as type soundness, which cannot even be expressed.We show that this issue is only apparent: the distinction between stuck and diverging computations is implicit in any big-step semantics and it just needs to be uncovered. To achieve this goal, we develop a systematic study of big-step semantics: we introduce an abstract definition of what a big-step semantics is, we define a notion of computation by formalizing the evaluation algorithm implicitly associated with any big-step semantics, and we show how to canonically extend a big-step semantics to characterize stuck and diverging computations.Building on these notions, we describe a general proof technique to show that a predicate is sound, that is, it prevents stuck computation, with respect to a big-step semantics. One needs to check three properties relating the predicate and the semantics, and if they hold, the predicate is sound. The extended semantics is essential to establish this meta-logical result but is of no concerns to the user, who only needs to prove the three properties of the initial big-step semantics. Finally, we illustrate the technique by several examples, showing that it is applicable also in cases where subject reduction does not hold, and hence the standard technique for small-step semantics cannot be used. © 2022 Association for Computing Machinery.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85135009157
"Racordon D., Shabalin D., Zheng D., Abrahams D., Saeta B.","57191479879;57204685287;57222420312;57222421889;57219748718;","Implementation Strategies for Mutable Value Semantics",2022,"Journal of Object Technology","21","2",,"","",,,"10.5381/jot.2022.21.2.a2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129681696&doi=10.5381%2fjot.2022.21.2.a2&partnerID=40&md5=e9cc1e40c122434b9e8db358249b94d9","Mutable value semantics is a programming discipline that upholds the independence of values to support local reasoning. In the discipline’s strictest form, references become second-class citizens: they are only created implicitly, at function boundaries, and cannot be stored in variables or object fields. Hence, variables can never share mutable state. Unlike pure functional programming, however, mutable value semantics allows part-wise in-place mutation, thereby eliminating the memory traffic usually associated with functional updates of immutable data. This paper presents implementation strategies for compiling programs with mutable value semantics into efficient native code. We study Swift, a programming language based on that discipline, through the lens of a core language that strips some of Swift’s features to focus on the semantics of its value types. The strategies that we introduce leverage the inherent properties of mutable value semantics to unlock aggressive optimizations. Fixed-size values are allocated on the stack, thereby enabling numerous off-the-shelf compiler optimizations, while dynamically sized containers use copy-on-write to mitigate copying costs. © 2022",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85129681696
"Veltri N., Voorneveld N.F.W.","57222564340;57196727884;","Inductive and Coinductive Predicate Liftings for Effectful Programs",2021,"Electronic Proceedings in Theoretical Computer Science, EPTCS","351",,,"260","277",,,"10.4204/EPTCS.351.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122280172&doi=10.4204%2fEPTCS.351.16&partnerID=40&md5=612bf4bbf5930267b8626873b724ffab","We formulate a framework for describing behaviour of effectful higher-order recursive programs. Examples of effects are implemented using effect operations, and include: execution cost, nondeterminism, global store and interaction with a user. The denotational semantics of a program is given by a coinductive tree in a monad, which combines potential return values of the program in terms of effect operations. Using a simple test logic, we construct two sorts of predicate liftings, which lift predicates on a result type to predicates on computations that produce results of that type, each capturing a facet of program behaviour. Firstly, we study inductive predicate liftings which can be used to describe effectful notions of total correctness. Secondly, we study coinductive predicate liftings, which describe effectful notions of partial correctness. The two constructions are dual in the sense that one can be used to disprove the other. The predicate liftings are used as a basis for an endogenous logic of behavioural properties for higher-order programs. The program logic has a derivable notion of negation, arising from the duality of the two sorts of predicate liftings, and it generates a program equivalence which subsumes a notion of bisimilarity. Appropriate definitions of inductive and coinductive predicate liftings are given for a multitude of effect examples. The whole development has been fully formalized in the Agda proof assistant. © N. Veltri & N.F.W. Voorneveld",Conference Paper,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85122280172
"Paraskevopoulou Z., Li J.M., Appel A.W.","56912389700;57228262400;7101635673;","Compositional optimizations for CertiCoq",2021,"Proceedings of the ACM on Programming Languages","5","ICFP","3473591","","",,2,"10.1145/3473591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113344592&doi=10.1145%2f3473591&partnerID=40&md5=12054a0ad870717e7c589fd6c53bb50b","Compositional compiler verification is a difficult problem that focuses on separate compilation of program components with possibly different verified compilers. Logical relations are widely used in proving correctness of program transformations in higher-order languages; however, they do not scale to compositional verification of multi-pass compilers due to their lack of transitivity. The only known technique to apply to compositional verification of multi-pass compilers for higher-order languages is parametric inter-language simulations (PILS), which is however significantly more complicated than traditional proof techniques for compiler correctness. In this paper, we present a novel verification framework for lightweight compositional compiler correctness. We demonstrate that by imposing the additional restriction that program components are compiled by pipelines that go through the same sequence of intermediate representations, logical relation proofs can be transitively composed in order to derive an end-to-end compositional specification for multi-pass compiler pipelines. Unlike traditional logical-relation frameworks, our framework supports divergence preservation - even when transformations reduce the number of program steps. We achieve this by parameterizing our logical relations with a pair of relational invariants. We apply this technique to verify a multi-pass, optimizing middle-end pipeline for CertiCoq, a compiler from Gallina (Coq's specification language) to C. The pipeline optimizes and closure-converts an untyped functional intermediate language (ANF or CPS) to a subset of that language without nested functions, which can be easily code-generated to low-level languages. Notably, our pipeline performs more complex closure-allocation optimizations than the state of the art in verified compilation. Using our novel verification framework, we prove an end-to-end theorem for our pipeline that covers both termination and divergence and applies to whole-program and separate compilation, even when different modules are compiled with different optimizations. Our results are mechanized in the Coq proof assistant. © 2021 Owner/Author.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85113344592
"Zakowski Y., Beck C., Yoon I., Zaichuk I., Zaliva V., Zdancewic S.","57195671199;57227894800;57220766056;57220899850;6508110433;57293474600;","Modular, compositional, and executable formal semantics for LLVM IR",2021,"Proceedings of the ACM on Programming Languages","5","ICFP","3473572","","",,,"10.1145/3473572","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113286107&doi=10.1145%2f3473572&partnerID=40&md5=8166b2aa6c7f5f031be2033110bfe6e2","This paper presents a novel formal semantics, mechanized in Coq, for a large, sequential subset of the LLVM IR. In contrast to previous approaches, which use relationally-specified operational semantics, this new semantics is based on monadic interpretation of interaction trees, a structure that provides a more compositional approach to defining language semantics while retaining the ability to extract an executable interpreter. Our semantics handles many of the LLVM IR's non-trivial language features and is constructed modularly in terms of event handlers, including those that deal with nondeterminism in the specification. We show how this semantics admits compositional reasoning principles derived from the interaction trees equational theory of weak bisimulation, which we extend here to better deal with nondeterminism, and we use them to prove that the extracted reference interpreter faithfully refines the semantic model. We validate the correctness of the semantics by evaluating it on unit tests and LLVM IR programs generated by HELIX. © 2021 Owner/Author.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85113286107
"Ciccone L., Dagnino F., Zucca E.","57210598548;57190810538;7005642627;","Flexible coinduction in Agda",2021,"Leibniz International Proceedings in Informatics, LIPIcs","193",,"13","","",,3,"10.4230/LIPIcs.ITP.2021.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113866702&doi=10.4230%2fLIPIcs.ITP.2021.13&partnerID=40&md5=7eb975befc2726fc7fbb948669078f52","We provide an Agda library for inference systems, also supporting their recent generalization allowing flexible coinduction, that is, interpretations which are neither inductive, nor purely coinductive. A specific inference system can be obtained as an instance by writing a set of meta-rules, in an Agda format which closely resembles the usual one. In this way, the user gets for free the related properties, notably the inductive and coinductive intepretation and the corresponding proof principles. Moreover, a significant modularity is achieved. Indeed, rather than being defined from scratch and with a built-in interpretation, an inference system can also be obtained by composition operators, such as union and restriction to a smaller universe, and its semantics can be modularly chosen as well. In particular, flexible coinduction is obtained by composing in a certain way the interpretations of two inference systems. We illustrate the use of the library by several examples. The most significant one is a big-step semantics for the λ-calculus, where flexible coinduction allows to obtain a special result (∞) for all and only the diverging computations, and the proof of equivalence with small-step semantics is carried out by relying on the proof principles offered by the library. © Luca Ciccone, Francesco Dagnino, and Elena Zucca.",Conference Paper,"Final","",Scopus,2-s2.0-85113866702
"Ancona D., Franceschini L., Ferrando A., Mascardi V.","7003625858;57195225535;55669011800;6506722954;","RML: Theory and practice of a domain specific language for runtime verification",2021,"Science of Computer Programming","205",,"102610","","",,4,"10.1016/j.scico.2021.102610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099367482&doi=10.1016%2fj.scico.2021.102610&partnerID=40&md5=54e3a98056f8fde84958252723c5b6de","Runtime verification (RV) is an approach to verification consisting in dynamically checking that the event traces generated by single runs of a system under scrutiny (SUS) are compliant with the formal specification of its expected correct behavior. RML (Runtime Monitoring Language) is a simple but powerful Domain Specific Language (DSL) for RV which is able to express non context-free properties. When designing RML, particular care has been taken to favor abstraction and simplicity, to better support reusability and portability of specifications and interoperability of the monitors generated from them; this is mainly achieved by decoupling the two problems of property specification and event generation, and by minimizing the available primitive constructs. The formalization and implementation of RML is based on a trace calculus with a fully deterministic rewriting semantics. The semantics of RML is defined by translation into such a calculus, which, in fact, is used as intermediate representation (IR) by the RML compiler. The effectiveness of RML and its methodological impact on RV are presented through interesting patterns that can be adapted to different contexts requiring verification of standard properties. A collection of tested examples is provided, together with benchmarks showing that the deterministic semantics and the performed dynamic optimizations based on the laws of the trace calculus significantly improve the performances of the generated monitors. © 2021 Elsevier B.V.",Article,"Final","",Scopus,2-s2.0-85099367482
"Dagnino F.","57190810538;","Foundations of regular coinduction",2021,"Logical Methods in Computer Science","17","4",,"2:1","2:29",,2,"10.46298/LMCS-17(4:2)2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116970367&doi=10.46298%2fLMCS-17%284%3a2%292021&partnerID=40&md5=9470b21b404fb3879f8094a95e938c08","Inference systems are a widespread framework used to define possibly recursive predicates by means of inference rules. They allow both inductive and coinductive interpre-tations that are fairly well-studied. In this paper, we consider a middle way interpretation, called regular, which combines advantages of both approaches: it allows non-well-founded reasoning while being finite. We show that the natural proof-theoretic definition of the regular interpretation, based on regular trees, coincides with a rational fixed point. Then, we provide an equivalent inductive characterization, which leads to an algorithm which looks for a regular derivation of a judgment. Relying on these results, we define proof techniques for regular reasoning: the regular coinduction principle, to prove completeness, and an inductive technique to prove soundness, based on the inductive characterization of the regular interpretation. Finally, we show the regular approach can be smoothly extended to inference systems with corules, a recently introduced, generalised framework, which allows one to refine the coinductive interpretation, proving that also this flexible regular interpretation admits an equivalent inductive characterisation. © F. Dagnino.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85116970367
"Cohen L.","56347969100;","Non-well-founded Deduction for Induction and Coinduction",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12699 LNAI",,,"3","24",,,"10.1007/978-3-030-79876-5_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112308335&doi=10.1007%2f978-3-030-79876-5_1&partnerID=40&md5=7ebfcf39fd8ed4b3ea20560d06b05dad","Induction and coinduction are both used extensively within mathematics and computer science. Algebraic formulations of these principles make the duality between them apparent, but do not account well for the way they are commonly used in deduction. Generally, the formalization of these reasoning methods employs inference rules that express a general explicit (co)induction scheme. Non-well-founded proof theory provides an alternative, more robust approach for formalizing implicit (co)inductive reasoning. This approach has been extremely successful in recent years in supporting implicit inductive reasoning, but is not as well-developed in the context of coinductive reasoning. This paper reviews the general method of non-well-founded proofs, and puts forward a concrete natural framework for (co)inductive reasoning, based on (co)closure operators, that offers a concise framework in which inductive and coinductive reasoning are captured as we intuitively understand and use them. Through this framework we demonstrate the enormous potential of non-well-founded deduction, both in the foundational theoretical exploration of (co)inductive reasoning and in the provision of proof support for (co)inductive reasoning within (semi-)automated proof tools. © 2021, The Author(s).",Conference Paper,"Final","All Open Access, Hybrid Gold",Scopus,2-s2.0-85112308335
"Racordon D., Buchs D.","57191479879;57205893866;","Featherweight Swift: A Core Calculus for Swift's Type System",2020,"SLE 2020 - Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, Co-located with SPLASH 2020",,,,"140","154",,2,"10.1145/3426425.3426939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097722244&doi=10.1145%2f3426425.3426939&partnerID=40&md5=7a1e2166a9ac787e2bcc04b5db1df205","Swift is a modern general-purpose programming language, designed to be a replacement for C-based languages. Although primarily directed at development of applications for Apple's operating systems, Swift's adoption has been growing steadily in other domains, ranging from server-side services to machine learning. This success can be partly attributed to a rich type system that enables the design of safe, fast, and expressive programming interfaces. Unfortunately, this richness comes at the cost of complexity, setting a high entry barrier to exploit Swift's full potential. Furthermore, existing documentation typically only relies on examples, leaving new users with little help to build a deeper understanding of the underlying rules and mechanisms. This paper aims to tackle this issue by laying out the foundations for a formal framework to reason about Swift's type system. We introduce Featherweight Swift, a minimal language stripped of all features not essential to describe its typing rules. Featherweight Swift features classes and protocol inheritance, supports retroactive modeling, and emulates Swift's overriding mechanisms. Yet its formalization fits on a few pages. We present Featherweight Swift's syntax and semantics. We then elaborate on the usability of our framework to reason about Swift's features, future extensions, and implementation by discussing a bug in Swift's compiler, discovered throughout the design of our calculus. © 2020 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85097722244
"Ancona D., Barbieri P., Dagnino F., Zucca E.","7003625858;57212132672;57190810538;7005642627;","Sound regular corecursion in coFJ",2020,"Leibniz International Proceedings in Informatics, LIPIcs","166",,"1","","",,3,"10.4230/LIPIcs.ECOOP.2020.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113417441&doi=10.4230%2fLIPIcs.ECOOP.2020.1&partnerID=40&md5=042e315180be1af447d19892e4ef8ba0","The aim of the paper is to provide solid foundations for a programming paradigm natively supporting the creation and manipulation of cyclic data structures. To this end, we describe coFJ, a Java-like calculus where objects can be infinite and methods are equipped with a codefinition (an alternative body). We provide an abstract semantics of the calculus based on the framework of inference systems with corules. In coFJ with this semantics, FJ recursive methods on finite objects can be extended to infinite objects as well, and behave as desired by the programmer, by specifying a codefinition. We also describe an operational semantics which can be directly implemented in a programming language, and prove the soundness of such semantics with respect to the abstract one. © Davide Ancona, Pietro Barbieri, Francesco Dagnino, and Elena Zucca.",Conference Paper,"Final","",Scopus,2-s2.0-85113417441
"Dagnino F., Ancona D., Zucca E.","57190810538;7003625858;7005642627;","Flexible coinductive logic programming",2020,"Theory and Practice of Logic Programming","20","6",,"818","833",,4,"10.1017/S147106842000023X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092007306&doi=10.1017%2fS147106842000023X&partnerID=40&md5=e73d41b8a95f563f635c038317030334","Recursive definitions of predicates are usually interpreted either inductively or coinductively. Recently, a more powerful approach has been proposed, called flexible coinduction, to express a variety of intermediate interpretations, necessary in some cases to get the correct meaning. We provide a detailed formal account of an extension of logic programming supporting flexible coinduction. Syntactically, programs are enriched by coclauses, clauses with a special meaning used to tune the interpretation of predicates. As usual, the declarative semantics can be expressed as a fixed point which, however, is not necessarily the least, nor the greatest one, but is determined by the coclauses. Correspondingly, the operational semantics is a combination of standard SLD resolution and coSLD resolution. We prove that the operational semantics is sound and complete with respect to declarative semantics restricted to finite comodels. ©",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85092007306
"Ancona D., Dagnino F., Rot J., Zucca E.","7003625858;57190810538;55305790900;7005642627;","A big step from finite to infinite computations",2020,"Science of Computer Programming","197",,"102492","","",,3,"10.1016/j.scico.2020.102492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086589422&doi=10.1016%2fj.scico.2020.102492&partnerID=40&md5=e33c6e5642b66690f89319575e3b6225","We provide a construction that, given a big-step semantics describing finite computations and their observations, extends it to include infinite computations as well. The basic idea is that the finite behavior uniquely determines the infinite behavior once observations and their composition operators are fixed. Technically, the construction relies on the framework of inference systems with corules. The effectiveness and scope of the approach are illustrated by several examples. The correctness is formally justified by proving that, starting from a big-step semantics equivalent to a reference small-step semantics, this equivalence is preserved by the construction. © 2020 Elsevier B.V.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-85086589422
"Zúñiga A., Bel-Enguix G.","57205416371;56635745900;","Coinductive Natural Semantics for Compiler Verification in Coq",2020,"Mathematics","8","9","1573","","",,,"10.3390/math8091573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091521836&doi=10.3390%2fmath8091573&partnerID=40&md5=8f2c74b936c85a477185e86c42496869","(Coinductive) natural semantics is presented as a unifying framework for the verification of total correctness of compilers in Coq (with the feature that a verified compiler can be obtained). In this way, we have a simple, easy, and intuitive framework; to carry out the verification of a compiler, using a proof assistant in which both cases are considered: terminating and non-terminating computations (total correctness). © 2020 by the authors.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-85091521836
"Momigliano A.","6602312633;","Why proof-theory matters in specification-based testing",2020,"CEUR Workshop Proceedings","2756",,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104258676&partnerID=40&md5=bc7f74812d1a444a691d53b5856a69ac","We survey some recent developments in giving a logical reconstruction of specification-based testing via the lenses of structural proof-theory. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). Partially supported by GNCS project “METALLIC #2: METodi di prova per il ragionamento Automatico per Logiche non-cLassIChe”.",Conference Paper,"Final","",Scopus,2-s2.0-85104258676
"Hardin D., Slind K., Pohjola J.Å., Sproul M.","7005216502;6602803304;56178736500;57224687253;","Synthesis of verified architectural components for critical systems hosted on a verified microkernel",2020,"Proceedings of the Annual Hawaii International Conference on System Sciences","2020-January",,,"6365","6374",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103499929&partnerID=40&md5=aa7e479bbbe5a91bbdadcafb71f1eedb","We describe a method and tools for the creation of formally verified components that run on the verified seL4 microkernel. This synthesis and verification environment provides a basis to create safe and secure critical systems. The mathematically proved space and time separation properties of seL4 are particularly well-suited for the miniaturised electronics of smaller, lower-cost Unmanned Aerial Vehicles (UAVs), as multiple, independent UAV applications can be hosted on a single CPU with high assurance. We illustrate our method and tools with an example that implements security-improving transformations on system architectures captured in the Architecture Analysis and Design Language (AADL). We show how input validation filter components can be synthesised from regular expressions, and verified to meet arithmetic constraints extracted from the AADL model. Such filters comprise efficient guards on messages to/from the autonomous system. The correctness proofs for filters are automatically lifted to proofs of the corresponding properties on the lazy streams that model the communications of the generated seL4 threads. Finally, we guarantee that the intent of the autonomy application logic is accurately reflected in the application binary code hosted on seL4 through the use of the verified CakeML compiler. © 2020 IEEE Computer Society. All rights reserved.",Conference Paper,"Final","",Scopus,2-s2.0-85103499929
"Jaloyan G.-A., Dross C., Maalej M., Moy Y., Paskevich A.","57192060591;42861173600;57189304727;23973568500;55990666200;","Verification of Programs with Pointers in SPARK",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12531 LNCS",,,"55","72",,,"10.1007/978-3-030-63406-3_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098242095&doi=10.1007%2f978-3-030-63406-3_4&partnerID=40&md5=121216bdd48f607145cf7265629acde8","In the field of deductive software verification, programs with pointers present a major challenge due to pointer aliasing. In this paper, we introduce pointers to SPARK, a well-defined subset of the Ada language, intended for formal verification of mission-critical software. Our solution uses a permission-based static alias analysis method inspired by Rust’s borrow-checker and affine types. To validate our approach, we have implemented it in the SPARK GNATprove formal verification toolset for Ada. In the paper, we give a formal presentation of the analysis rules for a core version of SPARK and discuss their implementation and scope. © 2020, Springer Nature Switzerland AG.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85098242095
"Cohen L., Rowe R.N.S.","56347969100;35180386000;","Integrating Induction and Coinduction via Closure Operators and Proof Cycles",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12166 LNAI",,,"375","394",,2,"10.1007/978-3-030-51074-9_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088235579&doi=10.1007%2f978-3-030-51074-9_21&partnerID=40&md5=cbc3288e33ab86f9d599689cd967fe0e","Coinductive reasoning about infinitary data structures has many applications in computer science. Nonetheless developing natural proof systems (especially ones amenable to automation) for reasoning about coinductive data remains a challenge. This paper presents a minimal, generic formal framework that uniformly captures applicable (i.e. finitary) forms of inductive and coinductive reasoning in an intuitive manner. The logic extends transitive closure logic, a general purpose logic for inductive reasoning based on the transitive closure operator, with a dual ‘co-closure’ operator that similarly captures applicable coinductive reasoning in a natural, effective manner. We develop a sound and complete non-well-founded proof system for the extended logic, whose cyclic subsystem provides the basis for an effective system for automated inductive and coinductive reasoning. To demonstrate the adequacy of the framework we show that it captures the canonical coinductive data type: streams. © 2020, Springer Nature Switzerland AG.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-85088235579
"Dagnino F., Bono V., Zucca E., Dezani-Ciancaglini M.","57190810538;57201262332;7005642627;57140196800;","Soundness Conditions for Big-Step Semantics",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12075 LNCS",,,"169","196",,3,"10.1007/978-3-030-44914-8_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083995217&doi=10.1007%2f978-3-030-44914-8_7&partnerID=40&md5=e1d608a1216e11d635517af5fcbb1745","We propose a general proof technique to show that a predicate is sound, that is, prevents stuck computation, with respect to a big-step semantics. This result may look surprising, since in big-step semantics there is no difference between non-terminating and stuck computations, hence soundness cannot even be expressed. The key idea is to define constructions yielding an extended version of a given arbitrary big-step semantics, where the difference is made explicit. The extended semantics are exploited in the meta-theory, notably they are necessary to show that the proof technique works. However, they remain transparent when using the proof technique, since it consists in checking three conditions on the original rules only, as we illustrate by several examples. © 2020, The Author(s).",Conference Paper,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85083995217
"Paviotti M., Cooksey S., Paradis A., Wright D., Owens S., Batty M.","57191897154;57216584758;57216588560;57216588125;7102978424;36968545700;","Modular Relaxed Dependencies in Weak Memory Concurrency",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12075 LNCS",,,"599","625",,11,"10.1007/978-3-030-44914-8_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083991181&doi=10.1007%2f978-3-030-44914-8_22&partnerID=40&md5=6ed5c1e9fc2ba7196d3130de12fc5ea7","We present a denotational semantics for weak memory concurrency that avoids thin-air reads, provides data-race free programs with sequentially consistent semantics (DRF-SC), and supports a compositional refinement relation for validating optimisations. Our semantics identifies false program dependencies that might be removed by compiler optimisation, and leaves in place just the dependencies necessary to rule out thin-air reads. We show that our dependency calculation can be used to rule out thin-air reads in any axiomatic concurrency model, in particular C++. We present a tool that automatically evaluates litmus tests, show that we can augment C++ to fix the thin-air problem, and we prove that our augmentation is compatible with the previously used compilation mappings over key processor architectures. We argue that our dependency calculation offers a practical route to fixing the longstanding problem of thin-air reads in the C++ specification. © 2020, The Author(s).",Conference Paper,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85083991181
"Ukasz Czajka Ł.","23395860300;","A new coinductive confluence proof for infinitary lambda calculus",2020,"Logical Methods in Computer Science","16","1","31","","",,2,"10.23638/LMCS-16(1:31)2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082109754&doi=10.23638%2fLMCS-16%281%3a31%292020&partnerID=40&md5=d9032b109d99a82093b5eb888523531c","We present a new and formal coinductive proof of confluence and normalisation of Böhm reduction in infinitary lambda calculus. The proof is simpler than previous proofs of this result. The technique of the proof is new, i.e., it is not merely a coinductive reformulation of any earlier proofs. We formalised the proof in the Coq proof assistant. © Ł. Czajka ○ Creative Commons.",Article,"Final","",Scopus,2-s2.0-85082109754
"Pohjola J.Å., Rostedt H., Myreen M.O.","56178736500;57211610247;23088605400;","Characteristic formulae for liveness properties of non-terminating CakeML programs",2019,"Leibniz International Proceedings in Informatics, LIPIcs","141",,"32","","",,7,"10.4230/LIPIcs.ITP.2019.32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074605520&doi=10.4230%2fLIPIcs.ITP.2019.32&partnerID=40&md5=59c87ef75bc5cd785341191604f1f6a9","There are useful programs that do not terminate, and yet standard Hoare logics are not able to prove liveness properties about non-terminating programs. This paper shows how a Hoare-like programming logic framework (characteristic formulae) can be extended to enable reasoning about the I/O behaviour of programs that do not terminate. The approach is inspired by transfinite induction rather than coinduction, and does not require non-terminating loops to be productive. This work has been developed in the HOL4 theorem prover and has been integrated into the ecosystem of proof tools surrounding the CakeML programming language. © Johannes Åman Pohjola, Henrik Rostedt, and Magnus O. Myreen.",Conference Paper,"Final","",Scopus,2-s2.0-85074605520
"Dagnino F.","57190810538;","A framework for big-step semantics",2019,"ACM International Conference Proceeding Series",,,"a27","","",,,"10.1145/3328433.3328461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072792579&doi=10.1145%2f3328433.3328461&partnerID=40&md5=de0cb67beb77c4c266cce4968e63d80b",[No abstract available],Conference Paper,"Final","",Scopus,2-s2.0-85072792579
"Liu X., Li X., Prajapati R., Wu D.","57221423152;57218926055;56160104400;42162348900;","DeepFuzz: Automatic generation of syntax valid C programs for fuzz testing",2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",,,,"1044","1051",,25,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076914174&partnerID=40&md5=0ec9042b6ac3eabd669a4353c79c8bba","Compilers are among the most fundamental programming tools for building software. However, production compilers remain buggy. Fuzz testing is often leveraged with newly-generated, or mutated inputs in order to find new bugs or security vulnerabilities. In this paper, we propose a grammar-based fuzzing tool called DEEPFUZZ. Based on a generative Sequence-to-Sequence model, DEEPFUZZ automatically and continuously generates well-formed C programs. We use this set of new C programs to fuzz off-the-shelf C compilers, e.g., GCC and Clang/LLVM. We present a detailed case study to analyze the success rate and coverage improvement of the generated C programs for fuzz testing. We analyze the performance of DEEPFUZZ with three types of sampling methods as well as three types of generation strategies. Consequently, DEEPFUZZ improved the testing efficacy in regards to the line, function, and branch coverage. In our preliminary study, we found and reported 8 bugs of GCC, all of which are actively being addressed by developers. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference Paper,"Final","",Scopus,2-s2.0-85076914174
"Mizuno M., Sumii E.","57194455436;6602549879;","Formal verifications of call-by-need and call-by-name evaluations with mutual recursion",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11893 LNCS",,,"181","201",,2,"10.1007/978-3-030-34175-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076706625&doi=10.1007%2f978-3-030-34175-6_10&partnerID=40&md5=ecc219cb166e57bce4af21db84c743a2","We present new proofs—formalized in the Coq proof assistant—of the correspondence among call-by-need and (various definitions of) call-by-name evaluations of λ-calculus with mutually recursive bindings. For non-strict languages, the equivalence between high-level specifications (call-by-name) and typical implementations (call-by-need) is of foundational interest. A particular milestone is Launchbury’s natural semantics of call-by-need evaluation and proof of its adequacy with respect to call-by-name denotational semantics, which are recently formalized in Isabelle/HOL by Breitner (2018). Equational theory by Ariola et al. is another well-known formalization of call-by-need. Mutual recursion is especially challenging for their theory: reduction is complicated by the traversal of dependency (the “need” relation), and the correspondence of call-by-name and call-by-need reductions becomes non-trivial, requiring sophisticated structures such as graphs or infinite trees. In this paper, we give arguably simpler proofs solely based on (finite) terms and operational semantics, which are easier to handle for proof assistants (Coq in our case). Our proofs can be summarized as follows: (1) we prove the equivalence between Launchbury’s call-by-need semantics and heap-based call-by-name natural semantics, where we define a sufficiently (but not too) general correspondence between the two heaps, and (2) we also show the correspondence among three styles of call-by-name semantics: (i) the natural semantics used in (1); (ii) closure-based natural semantics that informally corresponds to Launchbury’s denotational semantics; and (iii) conventional substitution-based semantics. © Springer Nature Switzerland AG 2019.",Conference Paper,"Final","",Scopus,2-s2.0-85076706625
"Dagnino F.","57190810538;","Coaxioms: Flexible coinductive definitions by inference systems",2019,"Logical Methods in Computer Science","15","1",,"26:1","26:48",,13,"10.23638/LMCS-15(1:26)2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070356277&doi=10.23638%2fLMCS-15%281%3a26%292019&partnerID=40&md5=46c6fed2e58964aa9555ea3b8047ced2","We introduce a generalized notion of inference system to support more exible interpretations of recursive definitions. Besides axioms and inference rules with the usual meaning, we allow also coaxioms, which are, intuitively, axioms which can only be applied “at infinite depth” in a proof tree. Coaxioms allow us to interpret recursive definitions as fixed points which are not necessarily the least, nor the greatest one, whose existence is guaranteed by a smooth extension of classical results. This notion nicely subsumes standard inference systems and their inductive and coinductive interpretation, thus allowing formal reasoning in cases where the inductive and coinductive interpretation do not provide the intended meaning, but are rather mixed together. © 2019 F. Dagnino. All rights reserved.",Article,"Final","",Scopus,2-s2.0-85070356277
"Altisen K., Corbineau P., Devismes S.","13002861000;23391807900;8922025800;","Squeezing Streams and Composition of Self-stabilizing Algorithms",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11535 LNCS",,,"21","38",,,"10.1007/978-3-030-21759-4_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067369612&doi=10.1007%2f978-3-030-21759-4_2&partnerID=40&md5=100a8676428f9a6ac509b1f61c05c2d6","Composition is a fundamental tool when dealing with complex systems. We study the hierarchical collateral composition which is used to combine self-stabilizing distributed algorithms. The PADEC library is a framework developed with the Coq proof assistant and dedicated to the certification of self-stabilizing algorithms. We enrich PADEC with the composition operator and a sufficient condition to show its correctness. The formal proof of the condition leads us to develop new tools and methods on potentially infinite streams, these latter ones being used to model the algorithms’ executions. The cornerstone has been the definition of the function which removes duplicates from streams. © 2019, IFIP International Federation for Information Processing.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85067369612
"Vesely F., Fisher K.","56426896700;57214548612;","One Step at a Time: A Functional Derivation of Small-Step Evaluators from Big-Step Counterparts",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11423 LNCS",,,"205","231",,,"10.1007/978-3-030-17184-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064891599&doi=10.1007%2f978-3-030-17184-1_8&partnerID=40&md5=4d948a8d5413a2a8058d34a7c99c3da0","Big-step and small-step are two popular flavors of operational semantics. Big-step is often seen as a more natural transcription of informal descriptions, as well as being more convenient for some applications such as interpreter generation or optimization verification. Small-step allows reasoning about non-terminating computations, concurrency and interactions. It is also generally preferred for reasoning about type systems. Instead of having to manually specify equivalent semantics in both styles for different applications, it would be useful to choose one and derive the other in a systematic or, preferably, automatic way. Transformations of small-step semantics into big-step have been investigated in various forms by Danvy and others. However, it appears that a corresponding transformation from big-step to small-step semantics has not had the same attention. We present a fully automated transformation that maps big-step evaluators written in direct style to their small-step counterparts. Many of the steps in the transformation, which include CPS-conversion, defunctionalisation, and various continuation manipulations, mirror those used by Danvy and his co-authors. For many standard languages, including those with either call-by-value or call-by-need and those with state, the transformation produces small-step semantics that are close in style to handwritten ones. We evaluate the applicability and correctness of the approach on 20 languages with a range of features. © The Author(s) 2019.",Conference Paper,"Final","All Open Access, Hybrid Gold, Green",Scopus,2-s2.0-85064891599
"Chrzaszcz J., Schubert A., Zakrzewski J.","22733519300;22434439600;34868863200;","Coq support in HAHA",2018,"Leibniz International Proceedings in Informatics, LIPIcs","97",,"8","","",,,"10.4230/LIPIcs.TYPES.2016.8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057002139&doi=10.4230%2fLIPIcs.TYPES.2016.8&partnerID=40&md5=b6a615d790e19aa077ca930cafc1605b","HAHA is a tool that helps in teaching and learning Hoare logic. It is targeted at an introductory course on software verification. We present a set of new features of the HAHA verification environment that exploit Coq. These features are (1) generation of verification conditions in Coq so that they can be explored and proved interactively and (2) compilation of HAHA programs into CompCert certified compilation tool-chain. With the interactive Coq proving support we obtain an interesting functionality that makes it possible to carefully examine step-by-step verification conditions and systematically discover flaws in their formulation. As a result Coq back-end serves as a kind of specification debugger. © Jacek Chrzaszcz, Aleksy Schubert, and Jakub Zakrzewski; licensed under Creative Commons License CC-BY 22nd International Conference on Types for Proofs and Programs (TYPES 2016).",Conference Paper,"Final","",Scopus,2-s2.0-85057002139
"Allombert V., Gava F., Tesson J.","56217786100;22733956400;24385840500;","A Formal Semantics of the MULTI-ML Language",2018,"Proceedings - 17th International Symposium on Parallel and Distributed Computing, ISPDC 2018",,,"8452036","180","187",,2,"10.1109/ISPDC2018.2018.00033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053897826&doi=10.1109%2fISPDC2018.2018.00033&partnerID=40&md5=d8ef359335e132bb19aea21cd82473cf","In the context of high performance computing, it is important to avoid indeterminism and dead-locks. Multi-ML is a functional parallel programming language 'à la ML', designed to program hierarchical architectures in a structured way. It is based of the Multi-BSP bridging model. To ensure that a program 'cannot go wrong', we first need to define how a program 'goes'. To do so, we propose a formal operational semantics of the Multi-ML language to ensure the properties of the Multi-BSP model. We first describe a core-language and then introduce the big step's semantics evaluation rules. Then, we propose a set of evaluation rules that describe the behaviour of the Multi-ML language. The memory model is also precisely defined, as the Multi-BSP model deals with multiple level of nested memories. © 2018 IEEE.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85053897826
"Ancona D., Dagnino F., Zucca E.","7003625858;57190810538;7005642627;","Modeling infinite behaviour by corules",2018,"Leibniz International Proceedings in Informatics, LIPIcs","109",,,"","",,7,"10.4230/LIPIcs.ECOOP.2018.21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052025635&doi=10.4230%2fLIPIcs.ECOOP.2018.21&partnerID=40&md5=80f3f348f610bdac2a6dd00c7d00d7cf","Generalized inference systems have been recently introduced, and used, among other applications, to define semantic judgments which uniformly model terminating computations and divergence. We show that the approach can be successfully extended to more sophisticated notions of infinite behaviour, that is, to express that a diverging computation produces some possibly infinite result. This also provides a motivation to smoothly extend the theory of generalized inference systems to include, besides coaxioms, also corules, a more general notion for which significant examples were missing until now. We first illustrate the approach on a λ-calculus with output effects, for which we also provide an alternative semantics based on standard notions, and a complete proof of the equivalence of the two semantics. Then, we consider a more involved example, that is, an imperative Java-like language with I/O primitives. © Davide Ancona, Francesco Dagnino, and Elena Zucca.",Conference Paper,"Final","",Scopus,2-s2.0-85052025635
"Kunze F., Smolka G., Forster Y.","57191570609;7003699258;57195678770;","Formal Small-Step Verification of a Call-by-Value Lambda Calculus Machine",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11275 LNCS",,,"264","283",,4,"10.1007/978-3-030-02768-1_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057787290&doi=10.1007%2f978-3-030-02768-1_15&partnerID=40&md5=09df956eb510b76bd0d9597f893d3caf","We formally verify an abstract machine for a call-by-value -calculus with de Bruijn terms, simple substitution, and small-step semantics. We follow a stepwise refinement approach starting with a naive stack machine with substitution. We then refine to a machine with closures, and finally to a machine with a heap providing structure sharing for closures. We prove the correctness of the three refinement steps with compositional small-step bottom-up simulations. There is an accompanying Coq development verifying all results. © 2018, Springer Nature Switzerland AG.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85057787290
"Dagnino F.","57190810538;","Flexible coinduction for infinite behaviour",2018,"CEUR Workshop Proceedings","2243",,,"17","23",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056885512&partnerID=40&md5=25a3c83a0334952f1cc76d4e31dfccb3","Generalized inference systems have been recently defined to overcome the strong dichotomy between inductive and coinductive interpretations. They support a flexible form of coinduction, subsuming even induction, which allows one to mediate between the two standard semantics. Recently, this framework has been successfully adopted to define semantic judgments which uniformly model finite and infinite computations. In this communication, we survey these results and outline directions for further developments. © 2018 CEUR-WS. All rights reserved.",Conference Paper,"Final","",Scopus,2-s2.0-85056885512
"Komauli F., Momigliano A.","57204057126;6602312633;","Property-based testing of the meta-theory of abstract machines: An experience report",2018,"CEUR Workshop Proceedings","2214",,,"22","39",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054338307&partnerID=40&md5=5d24ba1140279ce9d953fcd465421d94","Contrary to Dijkstra's diktat, testing, and more in general validation has found an increasing niche in formal verification, prior or even in alternative to theorem proving. In particular, property-based testing (PBT) is quite effective in mechanized meta-theory of programming languages, where theorems have shallow but tedious proofs that may go wrong for fairly banal mistakes. In this report, we abandon the comfort of high-level object languages and address the validation of abstract machines and typed assembly languages. We concentrate on Appel et al.'s list-machine benchmark [ADL12], which we tackle with αCheck, the simple model-checker on top of the nominal logic programming αProlog. We uncover one major bug in the published version of the paper plus several typos and ambiguities thereof. This is particularly striking, as the paper is accompanied by two full formalizations, in Coq and Twelf. Finally, we carry out some mutation testing on the given model, to asses the trade-off between exhaustive and randomized data generation, using for the latter the PBT library FSCheck for F#. Spoiler alert: aProlog performs better. © Copyright 2018 for the individual papers by the papers' authors.",Conference Paper,"Final","",Scopus,2-s2.0-85054338307
"Ancona D., Dagnino F., Zucca E.","7003625858;57190810538;7005642627;","Reasoning on divergent computations with coaxioms",2017,"Proceedings of the ACM on Programming Languages","1","OOPSLA","81","","",,11,"10.1145/3133905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083973751&doi=10.1145%2f3133905&partnerID=40&md5=d3df7dc8415c7247c298661aa53ce70c","Coaxioms have been recently introduced to enhance the expressive power of inference systems, by supporting interpretations which are neither purely inductive, nor coinductive. This paper proposes a novel approach based on coaxioms to capture divergence in semantic definitions by allowing inductive and coinductive semantic rules to be merged together for defining a unique semantic judgment. In particular, coinduction is used to derive a special result which models divergence. In this way, divergent, terminating, and stuck computations can be properly distinguished even in semantic definitions where this is typically difficult, as in big-step style. We show how the proposed approach can be applied to several languages; in particular, we first illustrate it on the paradigmatic example of the -calculus, then show how it can be adopted for defining the big-step semantics of a simple imperative Java-like language. We provide proof techniques to show classical results, including equivalence with small-step semantics, and type soundness for typed versions of both languages. © 2017 Copyright held by the owner/author(s).",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-85083973751
"Mizuno M., Sumii E.","57194455436;6602549879;","Formal verification of functional programs performing infinite input/output",2017,"Computer Software","34","2",,"114","119",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020198587&partnerID=40&md5=5132fa8c1a95d0f7fcf0afede337d840","Although formal verification of compilers is extensively studied, compilers for higher-order functional programming languages with side effects such as input and output are rarely verified. This is due to the difficulty of formalizing the semantics of programs performing infinite input and output. We have mechanically verified the K-normalization of call-by-value higher-order functional programs with recursive functions, pairs, and external function calls that can possibly cause side effects, by the Coq proof assistant. K-normalization is a program transformation that gives explicit names to all subexpressions via let-expressions. Its for-malization is non-trivial because of the manipulation of bindings. We defined the meanings of programs as infinite sequences of external function calls, using coinductive big-step operational semantics. We also adopted de Bruijn indices by comparison with other techniques to represent bindings.",Article,"Final","",Scopus,2-s2.0-85020198587
"Bach Poulsen C., Mosses P.D.","56592138600;6701810942;","Flag-based big-step semantics",2017,"Journal of Logical and Algebraic Methods in Programming","88",,,"174","190",,6,"10.1016/j.jlamp.2016.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025578212&doi=10.1016%2fj.jlamp.2016.05.001&partnerID=40&md5=e7127c54f6f515bc85a0b7e87828832b","Structural operational semantic specifications come in different styles: small-step and big-step. A problem with the big-step style is that specifying divergence and abrupt termination gives rise to annoying duplication. We present a novel approach to representing divergence and abrupt termination in big-step semantics using status flags. This avoids the duplication problem, and uses fewer rules and premises for representing divergence than previous approaches in the literature. © 2016 Elsevier Inc.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85025578212
"Allombert V., Gava F., Tesson J.","56217786100;22733956400;24385840500;","Multi-ML: Programming Multi-BSP Algorithms in ML",2017,"International Journal of Parallel Programming","45","2",,"340","361",,7,"10.1007/s10766-016-0417-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962132611&doi=10.1007%2fs10766-016-0417-6&partnerID=40&md5=57f1c2ba97dabf3bc06fa372d1dcec22","bsp is a bridging model between abstract execution and concrete parallel systems. Structure and abstraction brought by bsp allow to have portable parallel programs with scalable performance predictions, without dealing with low-level details of architectures. In the past, we designed bsml for programming bsp algorithms in ml. However, the simplicity of the bsp model does not fit the complexity of today’s hierarchical architectures such as clusters of machines with multiple multi-core processors. The multi-bsp model is an extension of the bsp model which brings a tree-based view of nested components of hierarchical architectures. To program multi-bsp algorithms in ml, we propose the multi-ml language as an extension of bsml where a specific kind of recursion is used to go through a hierarchy of computing nodes. We define a formal semantics of the language and present preliminary experiments which show performance improvements with respect to bsml. © 2016, Springer Science+Business Media New York.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-84962132611
"Amin N., Rompf T.","55602112900;35107892800;","Type soundness proofs with definitional interpreters",2017,"ACM SIGPLAN Notices","52","1",,"666","679",,3,"10.1145/3009837.3009866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119351253&doi=10.1145%2f3009837.3009866&partnerID=40&md5=b99c71baa1ce45ac2263f0dff566e0b6","While type soundness proofs are taught in every graduate PL class, the gap between realistic languages and what is accessible to formal proofs is large. In the case of Scala, it has been shown that its formal model, the Dependent Object Types (DOT) calculus, cannot simultaneously support key metatheoretic properties such as environment narrowing and subtyping transitivity, which are usually required for a type soundness proof. Moreover, Scala and many other realistic languages lack a general substitution property. The first contribution of this paper is to demonstrate how type soundness proofs for advanced, polymorphic, type systems can be carried out with an operational semantics based on high-level, definitional interpreters, implemented in Coq. We present the first mechanized soundness proofs in this style for System F and several extensions, including mutable references. Our proofs use only straightforward induction, which is significant, as the combination of big-step semantics, mutable references, and polymorphism is commonly believed to require coinductive proof techniques. The second main contribution of this paper is to show how DOT-like calculi emerge from straightforward generalizations of the operational aspects of F, exposing a rich design space of calculi with path-dependent types inbetween System F and DOT, which we dub the System D Square. By working directly on the target language, definitional interpreters can focus the design space and expose the invariants that actually matter at runtime. Looking at such runtime invariants is an exciting new avenue for type system design. © 2017 ACM.",Article,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85119351253
"Giannini P., Shaqiri A.","7004349370;55916154000;","A provably correct compilation of functional languages into scripting languages",2017,"Scientific Annals of Computer Science","27","1",,"19","76",,,"10.7561/SACS.2017.1.19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042416184&doi=10.7561%2fSACS.2017.1.19&partnerID=40&md5=744a32f5114697f42d3d5a00407af3a7","In this paper we consider the problem of translating core F#, a typed functional language including mutable variables and exception handling, into scripting languages such as JavaScript or Python. In previous work, we abstracted the most significant characteristics of scripting languages in an intermediate language (IL for short). IL is a block-structured imperative language in which a definition of a name does not have to statically precede its use. We define a big-step operational semantics for core F# and for IL and formalise the translation of F# expressions into IL. The main contribution of the paper is the proof of correctness of the given translation, which is done by showing that the evaluation of a well-typed F# program converges to a primitive value if and only if the evaluation of its translation into IL converges to the same value. © 2017, Alexandru Ioan Cuza University of Iasi. All rights reserved.",Article,"Final","All Open Access, Gold",Scopus,2-s2.0-85042416184
"Ancona D., Dagnino F., Zucca E.","7003625858;57190810538;7005642627;","Generalizing inference systems by coaxioms",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10201 LNCS",,,"29","55",,18,"10.1007/978-3-662-54434-1_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018674863&doi=10.1007%2f978-3-662-54434-1_2&partnerID=40&md5=20d7702cfec5836425a70e71ae0c37a8","We introduce a generalized notion of inference system to support structural recursion on non well-founded datatypes. Besides axioms and inference rules with the usual meaning, a generalized inference system allows coaxioms, which are, intuitively, axioms which can only be applied “at infinite depth” in a proof tree. This notion nicely subsumes standard inference systems and their inductive and coinductive interpretation, while providing more flexibility. Indeed, the classical results on the existence and constructive characterization of least and greatest fixed points can be extended to our generalized framework, interpreting recursive definitions as fixed points which are not necessarily the least, nor the greatest one. This allows formal reasoning in cases where the inductive and coinductive interpretation do not provide the intended meaning, or are mixed together. © Springer-Verlag GmbH Germany 2017.",Conference Paper,"Final","",Scopus,2-s2.0-85018674863
"Amin N., Rompf T.","55602112900;35107892800;","Type soundness proofs with definitional interpreters",2017,"Conference Record of the Annual ACM Symposium on Principles of Programming Languages",,,,"666","679",,34,"10.1145/3009837.3009866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015315833&doi=10.1145%2f3009837.3009866&partnerID=40&md5=5fb885c7b5ce0a72134d21bc890e1f56","While type soundness proofs are taught in every graduate PL class, the gap between realistic languages and what is accessible to formal proofs is large. In the case of Scala, it has been shown that its formal model, the Dependent Object Types (DOT) calculus, cannot simultaneously support key metatheoretic properties such as environment narrowing and subtyping transitivity, which are usually required for a type soundness proof. Moreover, Scala and many other realistic languages lack a general substitution property. The first contribution of this paper is to demonstrate how type soundness proofs for advanced, polymorphic, type systems can be carried out with an operational semantics based on high-level, definitional interpreters, implemented in Coq. We present the first mechanized soundness proofs in this style for System F<: and several extensions, including mutable references. Our proofs use only straightforward induction, which is significant, as the combination of big-step semantics, mutable references, and polymorphism is commonly believed to require coinductive proof techniques. The second main contribution of this paper is to show how DOT-like calculi emerge from straightforward generalizations of the operational aspects of F<:, exposing a rich design space of calculi with path-dependent types inbetween System F and DOT, which we dub the System D Square. By working directly on the target language, definitional interpreters can focus the design space and expose the invariants that actually matter at runtime. Looking at such runtime invariants is an exciting new avenue for type system design. © 2017 ACM.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85015315833
"Ancona D., Corradi A.","7003625858;36924831900;","Semantic subtyping for imperative object-oriented languages",2016,"ACM SIGPLAN Notices","51","10",,"568","587",,4,"10.1145/2983990.2983992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084584281&doi=10.1145%2f2983990.2983992&partnerID=40&md5=cca972d2322dd7885bc498af59f992bb","Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the defi- nition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record val- ues contain type information to specify the values that can be correctly stored in fields. Such a model, and the correspond- ing subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation. © 2016 ACM.",Article,"Final","",Scopus,2-s2.0-85084584281
"Ancona D., Corradi A.","7003625858;36924831900;","Semantic subtyping for imperative object-oriented languages",2016,"Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA","02-04-November-2016",,,"568","587",,6,"10.1145/2983990.2983992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995571206&doi=10.1145%2f2983990.2983992&partnerID=40&md5=8d170a7aa138a82c9708c05dedd7647d","Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the definition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record values contain type information to specify the values that can be correctly stored in fields. Such a model, and the corresponding subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation. © 2016 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84995571206
"Rodríguez L., Pagano M., Fridlender D.","56378353700;35113727800;55862105200;","Proving Correctness of a Compiler Using Step-indexed Logical Relations",2016,"Electronic Notes in Theoretical Computer Science","323",,,"197","214",,4,"10.1016/j.entcs.2016.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995542952&doi=10.1016%2fj.entcs.2016.06.013&partnerID=40&md5=cb41013dac13f5807a67a8a93b736755","In this paper we prove the correctness of a compiler for a call-by-name language using step-indexed logical relations and biorthogonality. The source language is an extension of the simply typed lambda-calculus with recursion, and the target language is an extension of the Krivine abstract machine. We formalized the proof in the Coq proof assistant. © 2016 The Author(s)",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-84995542952
"Poulsen C.B., Néron P., Tolmach A., Visser E.","56592138600;54787996300;6602314634;7004411487;","Scopes describe frames: A uniform model for memory layout in dynamic semantics",2016,"Leibniz International Proceedings in Informatics, LIPIcs","56",,,"201","2026",,6,"10.4230/LIPIcs.ECOOP.2016.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982798864&doi=10.4230%2fLIPIcs.ECOOP.2016.20&partnerID=40&md5=b1095051c71c0186f9bb6bf0a5d0cd71","Semantic specifications do not make a systematic connection between the names and scopes in the static structure of a program and memory layout, and access during its execution. In this paper we introduce a systematic approach to the alignment of names in static semantics and memory in dynamic semantics, building on the scope graph framework for name resolution. We develop a uniform memory model consisting of frames that instantiate the scopes in the scope graph of a program. This provides a language-independent correspondence between static scopes and run-time memory layout, and between static resolution paths and run-time memory access paths. The approach scales to a range of binding features, supports straightforward type soundness proofs, and provides the basis for a language-independent specification of sound reachabilitybased garbage collection. © Casper Bach Poulsen, Pierre Néron, Andrew Tolmach, and Eelco Visser; licensed under Creative Commons License CC-BY.",Conference Paper,"Final","",Scopus,2-s2.0-84982798864
"Cheney J., Momigliano A., Pessina M.","7005251362;6602312633;57190121541;","Advances in property-based testing for αprolog",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9762",,,"37","56",,10,"10.1007/978-3-319-41135-4_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977503558&doi=10.1007%2f978-3-319-41135-4_3&partnerID=40&md5=3e6052601fcfdd49c73b1a37f25b983b","αCheck is a light-weight property-based testing tool built on top of αProlog, a logic programming language based on nominal logic. αProlog is particularly suited to the validation of the meta-theory of formal systems, for example correctness of compiler translations involving name-binding, alpha-equivalence and capture-avoiding substitution. In this paper we describe an alternative to the negation elimination algorithm underlying αCheck that substantially improves its effectiveness. To substantiate this claim we compare the checker performances w.r.t. two of its main competitors in the logical framework niche, namely the QuickCheck/Nitpick combination offered by Isabelle/HOL and the random testing facility in PLT-Redex. © Springer International Publishing Switzerland 2016.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84977503558
"Owens S., Myreen M.O., Kumar R., Tan Y.K.","7102978424;23088605400;56329415700;56493680100;","Functional big-step semantics",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9632",,,"589","615",,51,"10.1007/978-3-662-49498-1_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961751168&doi=10.1007%2f978-3-662-49498-1_23&partnerID=40&md5=3454c7765ecf95e5c095941f1daa8d81","When doing an interactive proof about a piece of software, it is important that the underlying programming language’s semantics does not make the proof unnecessarily difficult or unwieldy. Both smallstep and big-step semantics are commonly used, and the latter is typically given by an inductively defined relation. In this paper, we consider an alternative: using a recursive function akin to an interpreter for the language. The advantages include a better induction theorem, less duplication, accessibility to ordinary functional programmers, and the ease of doing symbolic simulation in proofs via rewriting. We believe that this style of semantics is well suited for compiler verification, including proofs of divergence preservation. We do not claim the invention of this style of semantics: our contribution here is to clarify its value, and to explain how it supports several language features that might appear to require a relational or small-step approach. We illustrate the technique on a simple imperative language with C-like for-loops and a break statement, and compare it to a variety of other approaches. We also provide ML and lambda-calculus based examples to illustrate its generality. © Springer-Verlag Berlin Heidelberg 2016",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84961751168
"Danner N., Licata D.R., Ramyaa R.","14017877500;18437411800;36180114200;","Denotational cost semantics for functional languages with inductive types",2015,"ACM SIGPLAN Notices","50","9",,"140","151",,5,"10.1145/2784731.2784749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112822108&doi=10.1145%2f2784731.2784749&partnerID=40&md5=4f2236f0dbe6f0694c3c92051cdb50c1","A central method for analyzing the asymptotic complexity of a functional program is to extract and then solve a recurrence that expresses evaluation cost in terms of input size. The relevant notion of input size is often specific to a datatype, with measures including the length of a list, the maximum element in a list, and the height of a tree. In this work, we give a formal account of the extraction of cost and size recurrences from higher-order functional programs over inductive datatypes. Our approach allows a wide range of programmer-specified notions of size, and ensures that the extracted recurrences correctly predict evaluation cost. To extract a recurrence from a program, we first make costs explicit by applying a monadic translation from the source language to a complexity language, and then abstract datatype values as sizes. Size abstraction can be done semantically, working in models of the complexity language, or syntactically, by adding rules to a preorder judgement. We give several different models of the complexity language, which support different notions of size. Additionally, we prove by a logical relations argument that recurrences extracted by this process are upper bounds for evaluation cost; the proof is entirely syntactic and therefore applies to all of the models we consider. © 2015 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-85112822108
"Danner N., Licata D.R., Ramyaa R.","14017877500;18437411800;36180114200;","Denotational cost semantics for functional languages with inductive types",2015,"Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP","2015-August",,,"140","151",,30,"10.1145/2784731.2784749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957670461&doi=10.1145%2f2784731.2784749&partnerID=40&md5=429ecae862fd647ac0da78589dc0a2e3","A central method for analyzing the asymptotic complexity of a functional program is to extract and then solve a recurrence that expresses evaluation cost in terms of input size. The relevant notion of input size is often specific to a datatype, with measures including the length of a list, the maximum element in a list, and the height of a tree. In this work, we give a formal account of the extraction of cost and size recurrences from higher-order functional programs over inductive datatypes. Our approach allows a wide range of programmer-specified notions of size, and ensures that the extracted recurrences correctly predict evaluation cost. To extract a recurrence from a program, we first make costs explicit by applying a monadic translation from the source language to a complexity language, and then abstract datatype values as sizes. Size abstraction can be done semantically, working in models of the complexity language, or syntactically, by adding rules to a preorder judgement. We give several different models of the complexity language, which support different notions of size. Additionally, we prove by a logical relations argument that recurrences extracted by this process are upper bounds for evaluation cost; the proof is entirely syntactic and therefore applies to all of the models we consider.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84957670461
"Czajka U.","57132867700;","Confluence of nearly orthogonal infinitary term rewriting systems",2015,"Leibniz International Proceedings in Informatics, LIPIcs","36",,,"106","126",,2,"10.4230/LIPIcs.RTA.2015.106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958964649&doi=10.4230%2fLIPIcs.RTA.2015.106&partnerID=40&md5=fdf453132be730765793c5720dec64bc","terms, of nearly orthogonal infinitary term rewriting systems. Nearly orthogonal systems allow certain root overlaps, but no non-root overlaps. Using a slightly more complicated method we also show confluence modulo equivalence of hypercollapsing terms. The condition we impose on root overlaps is similar to the condition used by Toyama in the context of finitary rewriting. © Lukasz Czajka.",Conference Paper,"Final","",Scopus,2-s2.0-84958964649
"Nakata K., Uustalu T.","35102980400;6602585906;","A hoare logic for the coinductive trace-based big-step semantics of while",2015,"Logical Methods in Computer Science","11","1","1","","",32,5,"10.2168/LMCS-11(1:1)2015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927614414&doi=10.2168%2fLMCS-11%281%3a1%292015&partnerID=40&md5=05ed95784920c78b4fdf401d2b236930","In search for a foundational framework for reasoning about observable behavior of programs that may not terminate, we have previously devised a trace-based big-step semantics for While. In this semantics, both traces and evaluation (relating initial states of program runs to traces they produce) are defined coinductively. On terminating runs, this semantics agrees with the standard inductive state-based semantics. Here we present a Hoare logic counterpart of our coinductive trace-based semantics and prove it sound and complete. Our logic subsumes the standard partial-correctness state-based Hoare logic as well as the total-correctness variation: they are embeddable. In the converse direction, projections can be constructed: a derivation of a Hoare triple in our trace-based logic can be translated into a derivation in the state-based logic of a translated, weaker Hoare triple. Since we work with a constructive underlying logic, the range of program properties we can reason about has a fine structure; in particular, we can distinguish between termination and nondivergence, e.g., unbounded classically total search fails to be terminating, but is nonetheless nondivergent. Our metatheory is entirely constructive as well, and we have formalized it in Coq. © K. Nakata and T. Uustalu.",Article,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-84927614414
"Bodin M., Jensen T., Schmitt A.","54787341400;7401539622;8863229600;","Certified abstract interpretation with pretty-big-step semantics",2015,"CPP 2015 - Proceedings of the 2015 ACM Conference on Certified Programs and Proofs, co-located with POPL 2015",,,,"29","40",,5,"10.1145/2676724.2693174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967263021&doi=10.1145%2f2676724.2693174&partnerID=40&md5=d3f7960f6b9aebf669eae25a2082bac4","This paper describes an investigation into developing certified abstract interpreters from big-step semantics using the Coq proof assistant. We base our approach on Schmidt's abstract interpretation principles for natural semantics, and use a pretty-big-step (PBS) semantics, a semantic format proposed by Charguéraud. We propose a systematic representation of the PBS format and implement it in Coq. We then show how the semantic rules can be abstracted in a methodical fashion, independently of the chosen abstract domain, to produce a set of abstract inference rules that specify an abstract interpreter. We prove the correctness of the abstract interpreter in Coq once and for all, under the assumption that abstract operations faithfully respect the concrete ones. We finally show how to define correct-by-construction analyses: their correction amounts to proving they belong to the abstract semantics. © 2015 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84967263021
"Ramananandro T., Shao Z., Weng S.-C., Koenig J., Fu Y.","23028657400;7202244357;23399143500;56486983900;57189267878;","A compositional semantics for verified separate compilation and linking",2015,"CPP 2015 - Proceedings of the 2015 ACM Conference on Certified Programs and Proofs, co-located with POPL 2015",,,,"3","14",,13,"10.1145/2676724.2693167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966925849&doi=10.1145%2f2676724.2693167&partnerID=40&md5=460cbaff4b50e15744d0ae55996e9d45","Recent ground-breaking efforts such as CompCert have made a convincing case that mechanized verification of the compiler correctness for realistic C programs is both viable and practical. Unfortunately, existing verified compilers can only handle whole programs-this severely limits their applicability and prevents the linking of verified C programs with verified external libraries. In this paper, we present a novel compositional semantics for reasoning about open modules and for supporting verified separate compilation and linking. More specifically, we replace external function calls with explicit events in the behavioral semantics. We then develop a verified linking operator that makes lazy substitutions on (potentially reacting) behaviors by replacing each external function call event with a behavior simulating the requested function. Finally, we show how our new semantics can be applied to build a refinement infrastructure that supports both vertical composition and horizontal composition. © 2015 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84966925849
"Poulsen C.B., Mosses P.D., Torrini P.","56592138600;6701810942;35868255000;","Imperative polymorphism by store-based types as abstract interpretations",2015,"PEPM 2015 - Proceedings of the 2015 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, co-located with POPL 2015",,,,"3","8",,1,"10.1145/2678015.2682545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966731069&doi=10.1145%2f2678015.2682545&partnerID=40&md5=b27187262dcbbe9a8d31cfba362d0e7a","Dealing with polymorphism in the presence of imperative features is a long-standing open problem for Hindley-Milner type systems. A widely adopted approach is the value restriction, which inhibits polymorphic generalisation and unfairly rejects various programs that cannot go wrong. We consider abstract interpretation as a tool for constructing safe and precise type systems, and investigate how to derive store-based types by abstract interpretation. We propose store-based types as a type discipline that holds potential for interesting and flexible alternatives to the value restriction. © 2015 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84966731069
"Corradi A., Frassetto F.","36924831900;57008863300;","Infinite derivations as failures",2015,"CEUR Workshop Proceedings","1459",,,"19","24",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950323777&partnerID=40&md5=e79b0e3ab84117dd64fcd06151290b99","When operating on cyclic data, programmers have to take care in assuring that their programs will terminate; in our opinion, this is a task for the interpreter. We present a Prolog meta-interpreter that checks for the presence of cyclic computations at runtime and returns a failure if this is the case, thus allowing inductive predicates to properly deal with cyclic terms.",Conference Paper,"Final","",Scopus,2-s2.0-84950323777
"Wang P., Cuellar S., Chlipala A.","56395609700;56396834600;10041238300;","Compiler verification meets cross-language linking via data abstraction",2014,"Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA",,,,"675","690",,24,"10.1145/2660193.2660201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908304669&doi=10.1145%2f2660193.2660201&partnerID=40&md5=cb4f20a19c249bc890dab16a41139b81","Many real programs are written in multiple different programming languages, and supporting this pattern creates challenges for formal compiler verification.We describe our Coq verification of a compiler for a high-level language, such that the compiler correctness theorem allows us to derive partial-correctness Hoare-logic theorems for programs built by linking the assembly code output by our compiler and assembly code produced by other means. Our compiler supports such tricky features as storable cross-language function pointers, without giving up the usual benefits of being able to verify different compiler phases (including, in our case, two classic optimizations) independently. The key technical innovation is a mixed operational and axiomatic semantics for the source language, with a built-in notion of abstract data types, such that compiled code interfaces with other languages only through axiomatically specified methods that mutate encapsulated private data, represented in whatever formats are most natural for those languages. Copyright 2014 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84908304669
"Rodríguez L., Fridlender D., Pagano M.","56378353700;55862105200;35113727800;","A certified extension of the krivine machine for a call-by-name higher-order imperative language",2014,"Leibniz International Proceedings in Informatics, LIPIcs","26",,,"230","250",,1,"10.4230/LIPIcs.TYPES.2013.230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907791456&doi=10.4230%2fLIPIcs.TYPES.2013.230&partnerID=40&md5=decd87eb39831ce9b2d8a8821cff114e","In this paper we present a compiler that translates programs from an imperative higher-order language into a sequence of instructions for an abstract machine. We consider an extension of the Krivine machine for the call-by-name lambda calculus, which includes strict operators and imperative features. We show that the compiler is correct with respect to the big-step semantics of our language, both for convergent and divergent programs. © Leonardo Rodríguez, Daniel Fridlender, and Miguel Pagano.",Conference Paper,"Final","",Scopus,2-s2.0-84907791456
"Kumar R., Myreen M.O., Norrish M., Owens S.","56329415700;23088605400;15832391000;7102978424;","CakeML: A verified implementation of ML",2014,"Conference Record of the Annual ACM Symposium on Principles of Programming Languages",,,,"179","191",,157,"10.1145/2535838.2535841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893441789&doi=10.1145%2f2535838.2535841&partnerID=40&md5=86ca5402bac18a7f6545acf6a0946b17","We have developed and mechanically verified an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our verification effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitrary-precision arithmetic, and compiler bootstrapping. Our contributions are twofold. The first is simply in building a system that is end-to-end verified, demonstrating that each piece of such a verification effort can in practice be composed with the others, and ensuring that none of the pieces rely on any over-simplifying assumptions. The second is developing novel approaches to some of the more challenging aspects of the verification. In particular, our formally verified compiler can bootstrap itself: we apply the verified compiler to itself to produce a verified machine-code implementation of the compiler. Additionally, our compiler proof handles diverging input programs with a lightweight approach based on logical timeout exceptions. The entire development was carried out in the HOL4 theorem prover. © 2014 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84893441789
"Kumar R., Myreen M.O., Norrish M., Owens S.","56329415700;23088605400;15832391000;7102978424;","CakeML: A verified implementation of ML",2014,"ACM SIGPLAN Notices","49","1",,"179","191",,42,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894044866&partnerID=40&md5=336e67234aeb5f6f1e466460055795b7","We have developed and mechanically verified an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our verification effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitraryprecision arithmetic, and compiler bootstrapping. Our contributions are twofold. The first is simply in building a system that is end-to-end verified, demonstrating that each piece of such a verification effort can in practice be composed with the others, and ensuring that none of the pieces rely on any over-simplifying assumptions. The second is developing novel approaches to some of the more challenging aspects of the verification. In particular, our formally verified compiler can bootstrap itself: we apply the verified compiler to itself to produce a verified machine-code implementation of the compiler. Additionally, our compiler proof handles diverging input programs with a lightweight approach based on logical timeout exceptions. The entire development was carried out in the HOL4 theorem prover.",Conference Paper,"Final","",Scopus,2-s2.0-84894044866
"Bartoletti M., Cimoli T., Pinna G.M., Zunino R.","9536042900;55608349600;57198881668;8382815000;","Circular causality in event structures",2014,"Fundamenta Informaticae","134","3-4",,"219","259",,10,"10.3233/FI-2014-1101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912107554&doi=10.3233%2fFI-2014-1101&partnerID=40&md5=3a3192f3ce6b2722def2908f388aac79","We propose a model of events with circular causality, in the form of a conservative extension of Winskel's event structures. We study the relations between this new kind of event structures and Propositional Contract Logic. Provable atoms in the logic correspond to reachable events in our event structures. Furthermore, we show a correspondence between the configurations of this new brand of event structures and the proofs in a fragment of Propositional Contract Logic.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84912107554
"Ancona D.","7003625858;","How to prove type soundness of Java-like languages without forgoing big-step semantics",2014,"Proceedings for FTfJP 2014: The 16th Workshop on Formal Techniques for Java-Like Programs - Co-located with ECOOP 2014",,,,"","",,8,"10.1145/2635631.2635846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907383291&doi=10.1145%2f2635631.2635846&partnerID=40&md5=721fa40c733fc5f84609f3fb774a812c","Small-step operational semantics is the most commonly employed formalism for proving type soundness of statically typed programming languages, because of its ability to distinguish stuck from non-terminating computations, as opposed to big-step operational semantics. Despite this, big-step operational semantics is more abstract, and more useful for specifying interpreters. In previous work we have proposed a new proof technique to prove type soundness of a Java-like language expressed in terms of its big-step operational semantics. However the presented proof is rather involved, since it requires showing that the set of proof trees defining the semantic judgment forms a complete metric space when equipped with a specific distance function. In this paper we propose a more direct and abstract approach that exploits a standard and general compactness property of the metric space of values, that allows approximation of the coinductive big-step semantics in terms of the small-step one; in this way type soundness can be proved by standard mathematical induction. © 2014 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84907383291
"Koskinen E., Terauchi T.","28167568100;7004662755;","Local temporal reasoning",2014,"Proceedings of the Joint Meeting of the 23rd EACSL Annual Conference on Computer Science Logic, CSL 2014 and the 29th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2014",,,"59","","",,15,"10.1145/2603088.2603138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905977424&doi=10.1145%2f2603088.2603138&partnerID=40&md5=db903b397ff85619265d185000ce163b","We present the first method for reasoning about temporal logic properties of higher-order, infinite-data programs. By distinguishing between the finite traces and infinite traces in the specification, we obtain rules that permit us to reason about the temporal behavior of program parts via a type-and-effect system, which is then able to compose these facts together to prove the overall target property of the program. The type system alone is strong enough to derive many temporal safety properties using refinement types and temporal effects. We also show how existing techniques can be used as oracles to provide liveness information (e.g. termination) about program parts and that the type-and-effect system can combine this information with temporal safety information to derive nontrivial temporal properties. Our work has application toward verification of higher-order software, as well as modular strategies for procedural programs. Copyright © 2014 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84905977424
"Ancona D., Corradi A.","7003625858;36924831900;","Sound and complete subtyping between coinductive types for object-oriented languages",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","8586 LNCS",,,"282","307",,12,"10.1007/978-3-662-44202-9_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905370324&doi=10.1007%2f978-3-662-44202-9_12&partnerID=40&md5=f63bbd6a80f8a7d4958e7c69c3ec0b0f","Structural subtyping is an important notion for effective static type analysis; it can be defined either axiomatically by a collection of subtyping rules, or by means of set inclusion between type interpretations, following the more intuitive approach of semantic subtyping, which allows simpler proofs of the expected properties of the subtyping relation. In object-oriented programming, recursive types are typically interpreted inductively; however, cyclic objects can be represented more precisely by coinductive types. We study semantic subtyping between coinductive types with records and unions, which are particularly interesting for object-oriented programming, and develop and implement a sound and complete top-down direct and effective algorithm for deciding it. To our knowledge, this is the first proposal for a sound and complete top-down direct algorithm for semantic subtyping between coinductive types. © 2014 Springer-Verlag.",Conference Paper,"Final","",Scopus,2-s2.0-84905370324
"Bach Poulsen C., Mosses P.D.","56592138600;6701810942;","Deriving pretty-big-step semantics from small-step semantics",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","8410 LNCS",,,"270","289",,11,"10.1007/978-3-642-54833-8_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900564487&doi=10.1007%2f978-3-642-54833-8_15&partnerID=40&md5=cb4b3cd0796a39798136fb810cd8bc90","Big-step semantics for languages with abrupt termination and/or divergence suffer from a serious duplication problem, addressed by the novel 'pretty-big-step' style presented by Charguéraud at ESOP'13. Such rules are less concise than corresponding small-step rules, but they have the same advantages as big-step rules for program correctness proofs. Here, we show how to automatically derive pretty-big-step rules directly from small-step rules by 'refocusing'. This gives the best of both worlds: we only need to write the relatively concise small-step specifications, but our reasoning can be big-step as well as small-step. The use of strictness annotations to derive small-step congruence rules gives further conciseness. © 2014 Springer-Verlag.",Conference Paper,"Final","All Open Access, Bronze",Scopus,2-s2.0-84900564487
"Uustalu T.","6602585906;","Coinductive big-step semantics for concurrency",2013,"Electronic Proceedings in Theoretical Computer Science, EPTCS","137",,,"63","78",,3,"10.4204/EPTCS.137.6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954516018&doi=10.4204%2fEPTCS.137.6&partnerID=40&md5=6bcdc3fa6d56d7e62333fa0d2095ffc9","In a paper presented at SOS 2010 [13], we developed a framework for big-step semantics for interactive input-output in combination with divergence, based on coinductive and mixed inductive-coinductive notions of resumptions, evaluation and termination-sensitive weak bisimilarity. In contrast to standard inductively defined big-step semantics, this framework handles divergence properly; in particular, runs that produce some observable effects and then diverge, are not ""lost"". Here we scale this approach for shared-variable concurrency on a simple example language. We develop the metatheory of our semantics in a constructive logic.",Conference Paper,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-84954516018
"Ancona D.","7003625858;","Regular corecursion in Prolog",2013,"Computer Languages, Systems and Structures","39","4",,"142","162",,17,"10.1016/j.cl.2013.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888431632&doi=10.1016%2fj.cl.2013.05.001&partnerID=40&md5=8cb79c298afa5a9c0744cb8fbe63113d","Corecursion is the ability of defining a function that produces some infinite data in terms of the function and the data itself, as supported by lazy evaluation. However, in languages such as Haskell strict operations fail to terminate even on infinite regular data, that is, cyclic data. Regular corecursion is naturally supported by coinductive Prolog, an extension where predicates can be interpreted either inductively or coinductively, that has proved to be useful for formal verification, static analysis and symbolic evaluation of programs. In this paper we use the meta-programming facilities offered by Prolog to propose extensions to coinductive Prolog aiming to make regular corecursion more expressive and easier to program with. First, we propose a new interpreter to solve the problem of non-terminating failure as experienced with the standard semantics of coinduction (as supported, for instance, in SWI-Prolog). Another problem with the standard semantics is that predicates expressed in terms of existential quantification over a regular term cannot directly defined by coinduction; to this aim, we introduce finally clauses, to allow more flexibility in coinductive definitions. Then we investigate the possibility of annotating arguments of coinductive predicates, to restrict coinductive definitions to a subset of the arguments; this allows more efficient definitions, and further enhance the expressive power of coinductive Prolog. We investigate the effectiveness of such features by showing different example programs manipulating several kinds of cyclic values, ranging from automata and context free grammars to graphs and repeating decimals; the examples show how computations on cyclic values can be expressed with concise and relatively simple programs. The semantics defined by these vanilla meta-interpreters are an interesting starting point for a more mature design and implementation of coinductive Prolog. © 2013 Elsevier Ltd.",Article,"Final","",Scopus,2-s2.0-84888431632
"Ciobâcǎ S.","34869365700;","From small-step semantics to big-step semantics, automatically",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7940 LNCS",,,"347","361",,6,"10.1007/978-3-642-38613-8_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886073046&doi=10.1007%2f978-3-642-38613-8_24&partnerID=40&md5=7310ba57ef845cf4444a18ee9b8730ab","Small-step semantics and big-step semantics are two styles for operationally defining the meaning of programming languages. Small-step semantics are given as a relation between program configurations that denotes one computational step; big-step semantics are given as a relation directly associating to each program configuration the corresponding final configuration. Small-step semantics are useful for making precise reasonings about programs, but reasoning in big-step semantics is easier and more intuitive. When both small-step and big-step semantics are needed for the same language, a proof of the fact that the two semantics are equivalent should also be provided in order to trust that they both define the same language. We show that the big-step semantics can be automatically obtained from the small-step semantics when the small-step semantics are given by inference rules satisfying certain assumptions that we identify. The transformation that we propose is very simple and we show that when the identified assumptions are met, it is sound and complete in the sense that the two semantics are equivalent. For a strict subset of the identified assumptions, we show that the resulting big-step semantics is sound but not necessarily complete. We discuss our transformation on a number of examples. © 2013 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","",Scopus,2-s2.0-84886073046
"Rosu G., Stefanescu A., Ciobaca S., Moore B.M.","6603971839;42162188300;34869365700;37041568100;","One-path reachability logic",2013,"Proceedings - Symposium on Logic in Computer Science",,,"6571568","358","367",,46,"10.1109/LICS.2013.42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883333346&doi=10.1109%2fLICS.2013.42&partnerID=40&md5=ace6a49fcef08a08d595781df2e01988","This paper introduces(one-path) reach ability logic, a language-independent proof system for program verification, which takes an operational semantics as axioms and derivesreach ability rules, which generalize Hoare triples. This system improves on previous work by allowing operational semantics given withconditional* rewrite rules, which are known to support all major styles of operational semantics. In particular, Kahn's big-step and Plot kin's small-step semantic styles are now supported. The reach ability logic proof system is shown sound (i.e., partially correct) and (relatively) complete. Reach ability logic thus eliminates the need to independently define an axiomatic and an operational semantics for each language, and the non-negligible effort to prove the former sound and complete w.r.t. the latter. The soundness result has also been formalized in Coq, allowing reach ability logic derivations to serve as formal proof certificates that rely only on the operational semantics. © 2013 IEEE.",Conference Paper,"Final","",Scopus,2-s2.0-84883333346
"Schäfer M., Sridharan M., Dolby J., Tip F.","26427858100;56248412800;8837002700;57203108250;","Dynamic determinacy analysis",2013,"Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)",,,,"165","174",,35,"10.1145/2462156.2462168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883088928&doi=10.1145%2f2462156.2462168&partnerID=40&md5=e581e95ae50bdfcfe1c341ac2ec31988","We present an analysis for identifying determinate variables and expressions that always have the same value at a given program point. This information can be exploited by client analyses and tools to, e.g., identify dead code or specialize uses of dynamic language constructs such as eval, replacing them with equivalent static constructs. Our analysis is completely dynamic and only needs to observe a single execution of the program, yet the deter-minacy facts it infers hold for any execution. We present a formal soundness proof of the analysis for a simple imperative language, and a prototype implementation that handles full JavaScript. Finally, we report on two case studies that explored how static analysis for JavaScript could leverage the information gathered by dynamic determinacy analysis. We found that in some cases scalability of static pointer analysis was improved dramatically, and that many uses of runtime code generation could be eliminated. Copyright © 2013 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84883088928
"Schäfer M., Sridharan M., Dolby J., Tip F.","26427858100;56248412800;8837002700;57203108250;","Dynamic determinacy analysis",2013,"ACM SIGPLAN Notices","48","6",,"165","174",,19,"10.1145/2499370.2462168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880108774&doi=10.1145%2f2499370.2462168&partnerID=40&md5=cc606f15246bc509a386b817743d02ce","We present an analysis for identifying determinate variables and expressions that always have the same value at a given program point. This information can be exploited by client analyses and tools to, e.g., identify dead code or specialize uses of dynamic language constructs such as eval, replacing them with equivalent static constructs. Our analysis is completely dynamic and only needs to observe a single execution of the program, yet the determinacy facts it infers hold for any execution. We present a formal soundness proof of the analysis for a simple imperative language, and a prototype implementation that handles full JavaScript. Finally, we report on two case studies that explored how static analysis for JavaScript could leverage the information gathered by dynamic determinacy analysis. We found that in some cases scalability of static pointer analysis was improved dramatically, and that many uses of runtime code generation could be eliminated.",Conference Paper,"Final","",Scopus,2-s2.0-84880108774
"Danner N., Paykin J., Royer J.S.","14017877500;55582890800;7202753896;","A static cost analysis for a higher-order language",2013,"PLPV 2013 - Proceedings of the 2013 ACM SIGPLAN Workshop on Programming Languages Meets Program Verification, Co-located with POPL 2013",,,,"25","34",,23,"10.1145/2428116.2428123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873419135&doi=10.1145%2f2428116.2428123&partnerID=40&md5=2d2311c17db15e008b8c85705f430c60","We develop a static complexity analysis for a higher-order functional language with structural list recursion. The complexity of an expression is a pair consisting of a cost and a potential. The former is defined to be the size of the expression's evaluation derivation in a standard big-step operational semantics. The latter is a measure of the ""future"" cost of using the value of that expression. A translation function maps target expressions to complexities. Our main result is the following Soundness Theorem: If t is a term in the target language, then the cost component of ktk is an upper bound on the cost of evaluating t. The proof of the Soundness Theorem is formalized in Coq, providing certified upper bounds on the cost of any expression in the target language. Copyright © 2013 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84873419135
"Simmons R.J., Zerny I.","24512533200;33368417500;","A logical correspondence between natural semantics and abstract machines",2013,"Proceedings of the 15th Symposium on Principles and Practice of Declarative Programming, PPDP 2013",,,,"109","119",,1,"10.1145/2505879.2505899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885224877&doi=10.1145%2f2505879.2505899&partnerID=40&md5=85b7fb979a4e67d1ba875a38c3fe12b6","We present a logical correspondence between natural semantics and abstract machines. This correspondence enables the mechanical and fully-correct construction of an abstract machine from a natural semantics. Our logical correspondence mirrors the Reynolds functional correspondence, but we manipulate semantic specifications encoded in a logical framework instead of manipulating functional programs. Natural semantics and abstract machines are instances of substructural operational semantics. As a byproduct, using a substructural logical framework, we bring concurrent and stateful models into the domain of the logical correspondence. © 2013 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84885224877
"Leroy X.","57192117370;","Mechanized semantics for compiler verification",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7705 LNCS",,,"386","388",,9,"10.1007/978-3-642-35182-2_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872241773&doi=10.1007%2f978-3-642-35182-2_27&partnerID=40&md5=ed6ef02f866bfb5589dac08b649e4b75","The formal verification of compilers and related programming tools depends crucially on the availability of appropriate mechanized semantics for the source, intermediate and target languages. In this invited talk, I review various forms of operational semantics and their mechanization, based on my experience with the formal verification of the CompCert C compiler. ©Springer-Verlag 2012.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84872241773
"Nakano K.","35249137000;","Shall we juggle, coinductively?",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7679 LNCS",,,"160","172",,,"10.1007/978-3-642-35308-6_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869852715&doi=10.1007%2f978-3-642-35308-6_14&partnerID=40&md5=6c3a95184d8ac055b03fa5cee4f936cc","Buhler et al. presented a mathematical theory of toss juggling by regarding a toss pattern as an arithmetic function, where the function must satisfy a condition for the pattern to be valid. In this paper, the theory is formalized in terms of coinduction, reflecting the fact that the validity of toss juggling is related to a property of infinite phenomena. A tactic is implemented for proving the validity of toss patterns in Coq. Additionally, the completeness and soundness of a well-known algorithm for checking the validity is demonstrated. The result exposes a practical aspect of coinductive proofs. © 2012 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","",Scopus,2-s2.0-84869852715
"Tollitte P.-N., Delahaye D., Dubois C.","55496616200;8224781000;7103326256;","Producing certified functional code from inductive specifications",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7679 LNCS",,,"76","91",,12,"10.1007/978-3-642-35308-6_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869821055&doi=10.1007%2f978-3-642-35308-6_9&partnerID=40&md5=06f99a93bec02f8b7a225c31e88d0765","Proof assistants based on type theory allow the user to adopt either a functional style, or a relational style (e.g., by using inductive types). Both styles have pros and cons. Relational style may be preferred because it allows the user to describe only what is true, discard momentarily the termination question, and stick to a rule-based description. However, a relational specification is usually not executable. This paper proposes to turn an inductive specification into a functional one, in the logical setting itself, more precisely Coq in this work. We define for a certain class of inductive specifications a way to extract functions from them and automatically produce the proof of soundness of the extracted function w.r.t. its inductive specification. In addition, using user-defined modes which label inputs and outputs, we are able to extract several computational contents from a single inductive type. © 2012 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","",Scopus,2-s2.0-84869821055
"Leroy X.","57192117370;","Mechanized semantics for compiler verification",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7679 LNCS",,,"4","6",,3,"10.1007/978-3-642-35308-6_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869752686&doi=10.1007%2f978-3-642-35308-6_2&partnerID=40&md5=1fdfd82eec8ec2b5f866088ac903c101","The formal verification of compilers and related programming tools depends crucially on the availability of appropriate mechanized semantics for the source, intermediate and target languages. In this invited talk, I review various forms of operational semantics and their mechanization, based on my experience with the formal verification of the CompCert C compiler. © 2012 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84869752686
"Myreen M.O., Owens S.","23088605400;7102978424;","Proof-producing synthesis of ML from higher-order logic",2012,"Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP",,,,"115","126",,11,"10.1145/2364527.2364545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867544496&doi=10.1145%2f2364527.2364545&partnerID=40&md5=f29e830566d51039d7a401a11c6c22c4","The higher-order logic found in proof assistants such as Coq and various HOL systems provides a convenient setting for the development and verification of pure functional programs. However, to efficiently run these programs, they must be converted (or ""extracted"") to functional programs in a programming language such as ML or Haskell. With current techniques, this step, which must be trusted, relates similar looking objects that have very different semantic definitions, such as the set-theoretic model of a logic and the operational semantics of a programming language. In this paper, we show how to increase the trustworthiness of this step with an automated technique. Given a functional program expressed in higher-order logic, our technique provides the corresponding program for a functional language defined with an operational semantics, and it provides a mechanically checked theorem relating the two. This theorem can then be used to transfer verified properties of the logical function to the program. We have implemented our technique in the HOL4 theorem prover, translating functions to a core subset of Standard ML, and have applied it to examples including functional data structures, a parser generator, cryptographic algorithms, and a garbage collector. © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84867544496
"Momigliano A.","6602312633;","A supposedly fun thing I may have to do again: A HOAS encoding of Howe's method",2012,"LFMTP'12 - Proceedings of the ACM SIGPLAN Workshop on Logical Frameworks and Meta Languages, Theory and Practice",,,,"33","42",,12,"10.1145/2364406.2364411","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867527184&doi=10.1145%2f2364406.2364411&partnerID=40&md5=c06f9377872168d1a14695368dd4479e","We formally verify in Abella that similarity in the call-by-name lambda calculus is a pre-congruence, using Howe's method. This turns out to be a very challenging task for HOAS-based systems, as it entails a demanding combination of inductive and coinductive reasoning on open terms, for which no other existing HOAS-based system is equipped for. We also offer a proof using a version of Abella supplemented with predicate quantification; this results in a more structured presentation that is largely independent of the operational semantics as well of the chosen notion of (bi)similarity. While the end result is significantly more succinct and elegant than previous attempts, the exercise highlights some limitations of the two-level approach in general and of Abella in particular. © 2012 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84867527184
"Danielsson N.A.","22333411300;","Operational semantics using the partiality monad",2012,"Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP",,,,"127","138",,30,"10.1145/2364527.2364546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867499838&doi=10.1145%2f2364527.2364546&partnerID=40&md5=ebceb4148b0464b57209066dcfb560f7","The operational semantics of a partial, functional language is often given as a relation rather than as a function. The latter approach is arguably more natural: if the language is functional, why not take advantage of this when defining the semantics? One can immediately see that a functional semantics is deterministic and, in a constructive setting, computable. This paper shows how one can use the coinductive partiality monad to define big-step or small-step operational semantics for lambda-calculi and virtual machines as total, computable functions (total definitional interpreters). To demonstrate that the resulting semantics are useful type soundness and compiler correctness results are also proved. The results have been implemented and checked using Agda, a dependently typed programming language and proof assistant. © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84867499838
"Appel A.W., Dockins R., Leroy X.","7101635673;25421524200;57192117370;","A list-machine benchmark for mechanized metatheory",2012,"Journal of Automated Reasoning","49","3",,"453","491",,6,"10.1007/s10817-011-9226-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868600764&doi=10.1007%2fs10817-011-9226-1&partnerID=40&md5=20f6142483fb00d9f5d4c77448674452","We propose a benchmark to compare theorem-proving systems on their ability to express proofs of compiler correctness. In contrast to the first POPLmark, we emphasize the connection of proofs to compiler implementations, and we point out that much can be done without binders or alpha-conversion. We propose specific criteria for evaluating the utility of mechanized metatheory systems; we have constructed solutions in both Coq and Twelf metatheory, and we draw conclusions about those two systems in particular. © Springer Science+Business Media B.V. 2011.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-84868600764
"Correnson L., Signoles J.","35106711100;25522461600;","Combining analyses for C program verification",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7437 LNCS",,,"108","130",,20,"10.1007/978-3-642-32469-7_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866658740&doi=10.1007%2f978-3-642-32469-7_8&partnerID=40&md5=99fbfbc8f660fa4f76c1a6ecff118441","Static analyzers usually return partial results. They can assert that some properties are valid during all possible executions of a program, but generally leave some other properties to be verified by other means. In practice, it is common to combine results from several methods manually to achieve the full verification of a program. In this context, Frama-C is a platform for analyzing C source programs with multiple analyzers. Hence, one analyzer might conclude about properties assumed by another one, in the same environment. We present here the semantical foundations of validity of program properties in such a context. We propose a correct and complete algorithm for combining several partial results into a fully consolidated validity status for each program property. We illustrate how such a framework provides meaningful feedback on partial results. © 2012 Springer-Verlag.",Conference Paper,"Final","",Scopus,2-s2.0-84866658740
"Danielsson N.A.","22333411300;","Operational semantics using the partiality monad",2012,"ACM SIGPLAN Notices","47","9",,"127","138",,6,"10.1145/2398856.2364546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870458734&doi=10.1145%2f2398856.2364546&partnerID=40&md5=12cb7647fb070348fe946d7fc47a1b62","The operational semantics of a partial, functional language is often given as a relation rather than as a function. The latter approach is arguably more natural: if the language is functional, why not take advantage of this when defining the semantics? One can immediately see that a functional semantics is deterministic and, in a constructive setting, computable. This paper shows how one can use the coinductive partiality monad to define big-step or small-step operational semantics for lambda-calculi and virtual machines as total, computable functions (total definitional interpreters). To demonstrate that the resulting semantics are useful type soundness and compiler correctness results are also proved. The results have been implemented and checked using Agda, a dependently typed programming language and proof assistant. Copyright © 2012 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84870458734
"Myreen M.O., Owens S.","23088605400;7102978424;","Proof-producing synthesis of ML from higher-order logic",2012,"ACM SIGPLAN Notices","47","9",,"115","126",,6,"10.1145/2398856.2364545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870422874&doi=10.1145%2f2398856.2364545&partnerID=40&md5=dde64b3e532bb07a24b2f45560657fb4","The higher-order logic found in proof assistants such as Coq and various HOL systems provides a convenient setting for the development and verification of pure functional programs. However, to efficiently run these programs, they must be converted (or ""extracted"") to functional programs in a programming language such as ML or Haskell. With current techniques, this step, which must be trusted, relates similar looking objects that have very different semantic definitions, such as the set-theoretic model of a logic and the operational semantics of a programming language. In this paper, we show how to increase the trustworthiness of this step with an automated technique. Given a functional program expressed in higher-order logic, our technique provides the corresponding program for a functional language defined with an operational semantics, and it provides a mechanically checked theorem relating the two. This theorem can then be used to transfer verified properties of the logical function to the program. We have implemented our technique in the HOL4 theorem prover, translating functions to a core subset of Standard ML, and have applied it to examples including functional data structures, a parser generator, cryptographic algorithms, and a garbage collector. Copyright © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84870422874
"Ancona D.","7003625858;","Regular corecursion in Prolog",2012,"Proceedings of the ACM Symposium on Applied Computing",,,,"1897","1902",,5,"10.1145/2245276.2232088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863587409&doi=10.1145%2f2245276.2232088&partnerID=40&md5=494a97685e11d6d7fc7440d9120391aa","Co-recursion is the ability of defining a function that produces some infinite data in terms of the function and the data itself, and is typically supported by languages with lazy evaluation. However, in languages as Haskell strict operations fail to terminate even on infinite regular data. Regular co-recursion is naturally supported by co-inductive Prolog, an extension where predicates can be interpreted either inductively or co-inductively, that has proved to be useful for formal verification, static analysis and symbolic evaluation of programs. In this paper we propose two main alternative vanilla meta-interpreters to support regular co-recursion in Prolog as an interesting programming style in its own right, able to elegantly solve problems that would require more complex code if conventional recursion were used. In particular, the second meta-interpreters avoids non termination in several cases, by restricting the set of possible answers. The semantics defined by these vanilla meta-interpreters are an interesting starting point to study new semantics able to support regular co-recursion for non logical languages. © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84863587409
"Cave A., Pientka B.","55000224500;8909787800;","Programming with binders and indexed data-types",2012,"Conference Record of the Annual ACM Symposium on Principles of Programming Languages",,,,"413","424",,7,"10.1145/2103656.2103705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857830360&doi=10.1145%2f2103656.2103705&partnerID=40&md5=28d2f18379f2d8e49ee45e968526d80d","We show how to combine a general purpose type system for an existing language with support for programming with binders and contexts by refining the type system of ML with a restricted form of dependent types where index objects are drawn from contextual LF. This allows the user to specify formal systems within the logical framework LF and index ML types with contextual LF objects. Our language design keeps the index language generic only requiring decidability of equality of the index language providing a modular design. To illustrate the elegance and effectiveness of our language, we give programs for closure conversion and normalization by evaluation. Our three key technical contribution are: 1) We give a bidirectional type system for our core language which is centered around refinement substitutions instead of constraint solving. As a consequence, type checking is decidable and easy to trust, although constraint solving may be undecidable. 2) We give a big-step environment based operational semantics with environments which lends itself to efficient implementation. 3) We prove our language to be type safe and have mechanized our theoretical development in the proof assistant Coq using the fresh approach to binding. Copyright © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84857830360
"Herms P., Marché C., Monate B.","57216557799;56123550600;25522064900;","A certified multi-prover verification condition generator",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7152 LNCS",,,"2","17",,11,"10.1007/978-3-642-27705-4_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856552033&doi=10.1007%2f978-3-642-27705-4_2&partnerID=40&md5=7a711053dc422a175c7ca57185717594","Deduction-based software verification tools have reached a maturity allowing them to be used in industrial context where a very high level of assurance is required. This raises the question of the level of confidence we can grant to the tools themselves. We present a certified implementation of a verification condition generator. An originality is its genericity with respect to the logical context, which allows us to produce proof obligations for a large class of theorem provers. © 2012 Springer-Verlag.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84856552033
"Ancona D.","7003625858;","Soundness of object-oriented languages with coinductive big-step semantics",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7313 LNCS",,,"459","483",,13,"10.1007/978-3-642-31057-7_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879699076&doi=10.1007%2f978-3-642-31057-7_21&partnerID=40&md5=9b81dc6b28aac931b344347e95b316f0","It is well known that big-step operational semantics are not suitable for proving soundness of type systems, because of their inability to distinguish stuck from non-terminating computations. We show how this problem can be solved by interpreting coinductively the rules for the standard big-step operational semantics of a Java-like language, thus making the claim of soundness more intuitive: whenever a program is well-typed, its coinductive operational semantics returns a value. Indeed, coinduction allows non-terminating computations to return values; this is proved by showing that the set of proof trees defining the semantic judgment forms a complete metric space when equipped with a proper distance function. In this way, we are able to prove soundness of a nominal type system w.r.t. the coinductive semantics. Since the coinductive semantics is sound w.r.t. the usual small-step operational semantics, the standard claim of soundness can be easily deduced. © 2012 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","",Scopus,2-s2.0-84879699076
"Rośu G., Ştefǎnescu A.","6603971839;42162188300;","Towards a unified theory of operational and axiomatic semantics",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","7392 LNCS","PART 2",,"351","363",,20,"10.1007/978-3-642-31585-5_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869807192&doi=10.1007%2f978-3-642-31585-5_33&partnerID=40&md5=fd3a8b00ce6013dc510e2a84f51483f4","This paper presents a nine-rule language-independent proof system that takes an operational semantics as axioms and derives program reachability properties, including ones corresponding to Hoare triples. This eliminates the need for language-specific Hoare-style proof rules to verify programs, and, implicitly, the tedious step of proving such proof rules sound for each language separately. The key proof rule is Circularity, which is coinductive in nature and allows for reasoning about constructs with repetitive behaviors (e.g., loops). The generic proof system is shown sound and has been implemented in the MatchC verifier. © 2012 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84869807192
"Lago U.D., Zorzi M.","57201616133;24734296500;","Probabilistic operational semantics for the lambda calculus",2012,"RAIRO - Theoretical Informatics and Applications","46","3",,"413","450",,58,"10.1051/ita/2012012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868708253&doi=10.1051%2fita%2f2012012&partnerID=40&md5=7f58fbbfb7a43168310069b174b153e4","Probabilistic operational semantics for a nondeterministic extension of pure λ-calculus is studied. In this semantics, a term evaluates to a (finite or infinite) distribution of values. Small-step and big-step semantics, inductively and coinductively defined, are given. Moreover, small-step and big-step semantics are shown to produce identical outcomes, both in call-by-value and in call-by-name. Plotkin's CPS translation is extended to accommodate the choice operator and shown correct with respect to the operational semantics. Finally, the expressive power of the obtained system is studied: the calculus is shown to be sound and complete with respect to computable probability distributions. © EDP Sciences 2012.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-84868708253
"Cave A., Pientka B.","55000224500;8909787800;","Programming with binders and indexed data-types",2012,"ACM SIGPLAN Notices","47","1",,"413","424",,21,"10.1145/2103621.2103705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857161623&doi=10.1145%2f2103621.2103705&partnerID=40&md5=bab78eb6b2f88daa42e4ff54857a55c8","We show how to combine a general purpose type system for an existing language with support for programming with binders and contexts by refining the type system of ML with a restricted form of dependent types where index objects are drawn from contextual LF. This allows the user to specify formal systems within the logical framework LF and index ML types with contextual LF objects. Our language design keeps the index language generic only requiring decidability of equality of the index language providing a modular design. To illustrate the elegance and effectiveness of our language, we give programs for closure conversion and normalization by evaluation. Our three key technical contribution are: 1) We give a bidirectional type system for our core language which is centered around refinement substitutions instead of constraint solving. As a consequence, type checking is decidable and easy to trust, although constraint solving may be undecidable. 2) We give a big-step environment based operational semantics with environments which lends itself to efficient implementation. 3) We prove our language to be type safe and have mechanized our theoretical development in the proof assistant Coq using the fresh approach to binding. © 2012 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-84857161623
"Ancona D.","7003625858;","Coinductive big-step operational semantics for type soundness of Java-like languages",2011,"ECOOP 2011 Workshop Proceedings - 13th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2011",,,"5","","",,4,"10.1145/2076674.2076679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855713140&doi=10.1145%2f2076674.2076679&partnerID=40&md5=ed9364ce82369018271283df8ec8ba9a","We define a coinductive semantics for a simple Java-like language by simply interpreting coinductively the rules of a standard big-step operational semantics. We prove that such a semantics is sound w.r.t. the usual small-step operational semantics, and then prove soundness of a conventional nominal type system w.r.t. the coinductive semantics. From these two results, soundness of the type system w.r.t. the small-step semantics can be easily deduced. This new proposed approach not only opens up new possibilities for proving type soundness, but also provides useful insights on the connection between coinductive big-step operational semantics and type systems. Copyright 2011 ACM.",Conference Paper,"Final","All Open Access, Green",Scopus,2-s2.0-84855713140
"Colvin R.J., Hayes I.J.","35371596800;7004615706;","Structural operational semantics through context-dependent behaviour",2011,"Journal of Logic and Algebraic Programming","80","7",,"392","426",,6,"10.1016/j.jlap.2011.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959787370&doi=10.1016%2fj.jlap.2011.05.001&partnerID=40&md5=6d440a3e9d3c0f730c088f55919bad98","We present a new approach to providing a structural operational semantics for imperative programming languages with concurrency and procedures. The approach is novel because we expose the building block operations - variable assignment and condition checking - in the labels on the transitions; these form the context-dependent behaviour of a program. Using this style results in two main advantages over standard formalisms for imperative programming language semantics: firstly, our individual transition rules are more concise, and secondly, we are able to more abstractly and intuitively describe the semantics of procedures, including by-value and by-reference parameters. Standard techniques in the literature tend to result in complex and hard-to-read rules for even simple language constructs when procedures and parameters are dealt with. Our semantics for procedures utilises the context-dependent behaviour in the transition label to handle variable name scoping, and defines the semantics of recursion without requiring additional rules. In contrast with Plotkin's seminal structural operational semantics paper, we do not use locations to describe some of the more complex language constructs. Novel aspects of the abstract syntax include local states (in contrast to a single global store), which simplifies the reasoning about local variables, and a command for dynamically renaming variables (in contrast to mapping variables to locations), which simplifies the reasoning about the effect of procedures on by-reference parameters. © 2011 Elsevier Inc. All rights reserved.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-79959787370
"Sangiorgi D.","56238903200;","Introduction to bisimulation and coinduction",2011,"Introduction to Bisimulation and Coinduction","9781107003637",,,"1","247",,148,"10.1017/CBO9780511777110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923968279&doi=10.1017%2fCBO9780511777110&partnerID=40&md5=2661435ab0bdee444ba277ac70357363","Induction is a pervasive tool in computer science and mathematics for defining objects and reasoning on them. Coinduction is the dual of induction and as such it brings in quite different tools. Today, it is widely used in computer science, but also in other fields, including artificial intelligence, cognitive science, mathematics, modal logics, philosophy and physics. The best known instance of coinduction is bisimulation, mainly employed to define and prove equalities among potentially infinite objects: processes, streams, non-well-founded sets, etc. This book presents bisimulation and coinduction: the fundamental concepts and techniques and the duality with induction. Each chapter contains exercises and selected solutions, enabling students to connect theory with practice. A special emphasis is placed on bisimulation as a behavioural equivalence for processes. Thus the book serves as an introduction to models for expressing processes (such as process calculi) and to the associated techniques of operational and algebraic analysis. © D. Sangiorgi 2012.",Book,"Final","",Scopus,2-s2.0-84923968279
"Ancona D., Lagorio G.","7003625858;56618171700;","Idealized coinductive type systems for imperative object-oriented programs",2011,"RAIRO - Theoretical Informatics and Applications","45","1",,"3","33",,12,"10.1051/ita/2011009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855692394&doi=10.1051%2fita%2f2011009&partnerID=40&md5=520c12a8383902086eca4c0013730574","In recent work we have proposed a novel approach to define idealized type systems for object-oriented languages, based on abstract compilation of programs into Horn formulas which are interpreted w.r.t. the coinductive (that is, the greatest) Herbrand model. In this paper we investigate how this approach can be applied also in the presence of imperative features. This is made possible by considering a natural translation of Static Single Assignment intermediate form programs into Horn formulas, where φ functions correspond to union types. © 2011 EDP Sciences.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-84855692394
"Danielsson N.A., Altenkirch T.","22333411300;22333517400;","Subtyping, declaratively: An exercise in mixed induction and coinduction",2010,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","6120 LNCS",,,"100","118",,30,"10.1007/978-3-642-13321-3_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249243672&doi=10.1007%2f978-3-642-13321-3_8&partnerID=40&md5=b1d8d3b5a455596a47715b6523c370df","It is natural to present subtyping for recursive types coinductively. However, Gapeyev, Levin and Pierce have noted that there is a problem with coinductive definitions of non-trivial transitive inference systems: they cannot be ""declarative""-as opposed to ""algorithmic"" or syntax-directed-because coinductive inference systems with an explicit rule of transitivity are trivial. We propose a solution to this problem. By using mixed induction and coinduction we define an inference system for subtyping which combines the advantages of coinduction with the convenience of an explicit rule of transitivity. The definition uses coinduction for the structural rules, and induction for the rule of transitivity. We also discuss under what conditions this technique can be used when defining other inference systems. The developments presented in the paper have been mechanised using Agda, a dependently typed programming language and proof assistant. © 2010 Springer-Verlag Berlin Heidelberg.",Conference Paper,"Final","",Scopus,2-s2.0-78249243672
"Nakata K., Uustalu T.","35102980400;6602585906;","Resumptions, weak bisimilarity and big-step semantics for while with interactive I/O: An exercise in mixed induction-coinduction",2010,"Electronic Proceedings in Theoretical Computer Science, EPTCS","32",,,"57","75",,31,"10.4204/EPTCS.32.5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954532658&doi=10.4204%2fEPTCS.32.5&partnerID=40&md5=dcef2548dfb0e0995de42358aaceeec4","We look at the operational semantics of languages with interactive I/O through the glasses of constructive type theory. Following on from our earlier work on coinductive trace-based semantics for While [17], we define several big-step semantics for While with interactive I/O, based on resumptions and termination-sensitive weak bisimilarity. These require nesting inductive definitions in coinductive definitions, which is interesting both mathematically and from the point-of-view of implementation in a proof assistant. After first defining a basic semantics of statements in terms of resumptions with explicit internal actions (delays), we introduce a semantics in terms of delay-free resumptions that essentially removes finite sequences of delays on the fly from those resumptions that are responsive. Finally, we also look at a semantics in terms of delay-free resumptions supplemented with a silent divergence option. This semantics hinges on decisions between convergence and divergence and is only equivalent to the basic one classically. We have fully formalized our development in Coq.",Conference Paper,"Final","All Open Access, Gold, Green",Scopus,2-s2.0-84954532658
"Chlipala A.","10041238300;","A verified compiler for an impure functional language",2010,"Conference Record of the Annual ACM Symposium on Principles of Programming Languages",,,,"93","106",,38,"10.1145/1706299.1706312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950884123&doi=10.1145%2f1706299.1706312&partnerID=40&md5=0e329cdb018652d8f653949e0a1470a6","We present a verified compiler to an idealized assembly language from a small, untyped functional language with mutable references and exceptions. The compiler is programmed in the Coq proof assistant and has a proof of total correctness with respect to big-step operational semantics for the source and target languages. Compilation is staged and includes standard phases like translation to continuation-passing style and closure conversion, as well as a common subexpression elimination optimization. In this work, our focus has been on discovering and using techniques that make our proofs easy to engineer and maintain. While most programming language work with proof assistants uses very manual proof styles, all of our proofs are implemented as adaptive programs in Coq's tactic language, making it possible to reuse proofs unchanged as new language features are added. In this paper, we focus especially on phases of compilation that rearrange the structure of syntax with nested variable binders. That aspect has been a key challenge area in past compiler verification projects, with much more effort expended in the statement and proof of binder-related lemmas than is found in standard pencil-and-paper proofs. We show how to exploit the representation technique of parametric higher-order abstract syntax to avoid the need to prove any of the usual lemmas about binder manipulation, often leading to proofs that are actually shorter than their pencil-and-paper analogues. Our strategy is based on a new approach to encoding operational semantics which delegates all concerns about substitution to the meta language, without using features incompatible with general-purpose type theories like Coq's logic. Copyright © 2010 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-77950884123
"Nakata K., Uustalu T.","35102980400;6602585906;","A Hoare logic for the Coinductive trace-based big-step semantics of while",2010,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","6012",,,"488","506",,23,"10.1007/978-3-642-11957-6_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052024804&doi=10.1007%2f978-3-642-11957-6_26&partnerID=40&md5=30f18e5ff90c6191fb8d4ab64a8a6a83","In search for a foundational framework for reasoning about observable behavior of programs that may not terminate, we have previously devised a trace-based big-step semantics for While. In this semantics, both traces and evaluation (relating initial states of program runs to traces they produce) are defined coinductively. On terminating runs, it agrees with the standard inductive state-based semantics. Here we present a Hoare logic counterpart of our coinductive trace-based semantics and prove it sound and complete. Our logic subsumes both the partial correctness Hoare logic and the total correctness Hoare logic: they are embeddable. Since we work with a constructive underlying logic, the range of expressible program properties has a rich structure; in particular, we can distinguish between termination and nondivergence, e.g., unbounded total search fails to be terminating but is nonetheless nondivergent. Our metatheory is entirely constructive as well, and we have formalized it in Coq. © Springer-Verlag Berlin Heidelberg 2010.",Conference Paper,"Final","All Open Access, Bronze, Green",Scopus,2-s2.0-85052024804
"Chlipala A.","10041238300;","A verified compiler for an impure functional language",2010,"ACM SIGPLAN Notices","45","1",,"93","106",,32,"10.1145/1707801.1706312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77149154376&doi=10.1145%2f1707801.1706312&partnerID=40&md5=6d04b86b64c2869e341b441b20e4bb98","We present a verified compiler to an idealized assembly language from a small, untyped functional language with mutable references and exceptions. The compiler is programmed in the Coq proof assistant and has a proof of total correctness with respect to bigstep operational semantics for the source and target languages. Compilation is staged and includes standard phases like translation to continuation-passing style and closure conversion, as well as a common subexpression elimination optimization. In this work, our focus has been on discovering and using techniques that make our proofs easy to engineer and maintain. While most programming language work with proof assistants uses very manual proof styles, all of our proofs are implemented as adaptive programs in Coq's tactic language, making it possible to reuse proofs unchanged as new language features are added. In this paper, we focus especially on phases of compilation that rearrange the structure of syntax with nested variable binders. That aspect has been a key challenge area in past compiler verification projects, with much more effort expended in the statement and proof of binder-related lemmas than is found in standard penciland-paper proofs. We show how to exploit the representation technique of parametric higher-order abstract syntax to avoid the need to prove any of the usual lemmas about binder manipulation, often leading to proofs that are actually shorter than their pencil-andpaper analogues. Our strategy is based on a new approach to encoding operational semantics which delegates all concerns about substitution to the meta language, without using features incompatible with general-purpose type theories like Coq's logic. Copyright © 2010 ACM 978-1-60558-479-9/10/ 01⋯ $10.00.",Conference Paper,"Final","",Scopus,2-s2.0-77149154376
"Benton N., Hur C.-K.","8982524200;56184835000;","Biorthogonality, Step-indexing and compiler correctness",2009,"Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP",,,,"97","107",,58,"10.1145/1596550.1596567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450177976&doi=10.1145%2f1596550.1596567&partnerID=40&md5=dfad7ab8db51e6b1d48fa8bfd8030849","We define logical relations between the denotational semantics of a simply typed functional language with recursion and the operational behaviour of low-level programs in a variant SECD machine. The relations, which are defined using biorthogonality and stepindexing, capture what it means for a piece of low-level code to implement a mathematical, domain-theoretic function and are used to prove correctness of a simple compiler. The results have been formalized in the Coq proof assistant. Copyright © 2009 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-70450177976
"Nakata K., Uustalu T.","35102980400;6602585906;","Trace-based coinductive operational semantics for while",2009,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","5674 LNCS",,,"375","390",,32,"10.1007/978-3-642-03359-9_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350325123&doi=10.1007%2f978-3-642-03359-9_26&partnerID=40&md5=1b3cd986032201ff00e99aeb33aea56e","We present four coinductive operational semantics for the While language accounting for both terminating and non-terminating program runs: big-step and small-step relational semantics and big-step and small-step functional semantics. The semantics employ traces (possibly infinite sequences of states) to record the states that program runs go through. The relational semantics relate statement-state pairs to traces, whereas the functional semantics return traces for statement-state pairs. All four semantics are equivalent. We formalize the semantics and their equivalence proofs in the constructive setting of Coq. © 2009 Springer.",Conference Paper,"Final","",Scopus,2-s2.0-70350325123
"Nestra H.","6508256905;","Transfinite Semantics in the Form of Greatest Fixpoint",2009,"Journal of Logic and Algebraic Programming","78","7",,"573","592",,5,"10.1016/j.jlap.2009.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69349090631&doi=10.1016%2fj.jlap.2009.03.001&partnerID=40&md5=46a1f2188be2aa61d0ea5d7ae7b990c1","Transfinite semantics is a semantics according to which program executions can continue working after an infinite number of steps. Such a view of programs can be useful in the theory of program transformations. So far, transfinite semantics have been succesfully defined for iterative loops. This paper provides an exhaustive definition for semantics that enable also infinitely deep recursion. The definition is actually a parametric schema that defines a family of different transfinite semantics. As standard semantics also match the same schema, our framework describes both standard and transfinite semantics in a uniform way. All semantics are expressed as greatest fixpoints of monotone operators on some complete lattices. It turns out that, for transfinite semantics, the corresponding lattice operators are cocontinuous. According to Kleene's theorem, this shows that transfinite semantics can be expressed as a limit of iteration which is not transfinite. © 2009 Elsevier Inc. All rights reserved.",Article,"Final","All Open Access, Bronze",Scopus,2-s2.0-69349090631
"Blazy S., Leroy X.","56121762800;57192117370;","Mechanized Semantics for the Clight Subset of the C Language",2009,"Journal of Automated Reasoning","43","3",,"263","288",,112,"10.1007/s10817-009-9148-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349601646&doi=10.1007%2fs10817-009-9148-3&partnerID=40&md5=1760b3bfdf1b4d86896192fee2fcc184","This article presents the formal semantics of a large subset of the C language called Clight. Clight includes pointer arithmetic, struct and union types, C loops and structured switch statements. Clight is the source language of the CompCert verified compiler. The formal semantics of Clight is a big-step operational semantics that observes both terminating and diverging executions and produces traces of input/output events. The formal semantics of Clight is mechanized using the Coq proof assistant. In addition to the semantics of Clight, this article describes its integration in the CompCert verified compiler and several ways by which the semantics was validated. © 2009 Springer Science+Business Media B.V.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-70349601646
"Leroy X.","57192117370;","A formally verified compiler back-end",2009,"Journal of Automated Reasoning","43","4",,"363","446",,304,"10.1007/s10817-009-9155-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70849111798&doi=10.1007%2fs10817-009-9155-4&partnerID=40&md5=71fe35abea051d19027a0b9c6b305df3","This article describes the development and formal verification (proof of semantic preservation) of a compiler back-end from Cminor (a simple imperative intermediate language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its soundness. Such a verified compiler is useful in the context of formal methods applied to the certification of critical software: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well. © 2009 Springer Science+Business Media B.V.",Article,"Final","All Open Access, Green",Scopus,2-s2.0-70849111798
"Benton N., Hur C.-K.","8982524200;56184835000;","Biorthogonality, step-indexing and compiler correctness",2009,"ACM SIGPLAN Notices","44","9",,"97","107",,23,"10.1145/1631687.1596567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350450923&doi=10.1145%2f1631687.1596567&partnerID=40&md5=63f305cab853e6ef9b6cb1e8a156af3b","We define logical relations between the denotational semantics of a simply typed functional language with recursion and the operational behaviour of low-level programs in a variant SECD machine. The relations, which are defined using biorthogonality and stepindexing, capture what it means for a piece of low-level code to implement a mathematical, domain-theoretic function and are used to prove correctness of a simple compiler. The results have been formalized in the Coq proof assistant. &copy; 2009 ACM.",Conference Paper,"Final","",Scopus,2-s2.0-70350450923
